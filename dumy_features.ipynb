{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 99)\n",
    "\n",
    "FOLDER = \"/media/shared_ardalan_evgeny/processed_data/\"\n",
    "CORPUS  = \"test\"\n",
    "FEATURE = \"attrsJSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tryDivide(x, y):\n",
    "    \"\"\" Try to divide two numbers \"\"\"\n",
    "    s = 0.0\n",
    "    if y != 0.0: s = x / y\n",
    "    return s\n",
    "\n",
    "def getWordCharCount(w):\n",
    "    \"\"\" Char count for a word \"\"\"\n",
    "    rus = len(re.findall(r\"[а-я]\",w))\n",
    "    eng = len(re.findall(r\"[a-z]\",w))\n",
    "    c = len(w)    \n",
    "    return c, rus, eng\n",
    "\n",
    "def getTextStatsFeat(text, text_processed = False):\n",
    "    \n",
    "    \"\"\" Get stats features for raw text \"\"\"\n",
    "    sentenceCount = 0.0\n",
    "    exclamationMarkCount = 0.0\n",
    "    questionMarkCount = 0.0\n",
    "    \n",
    "    if not text_processed :\n",
    "        sentenceCount = len(re.findall(\"[.?!]\", text))\n",
    "        exclamationMarkCount = len(re.findall(\"[!]\", text))\n",
    "        questionMarkCount = len(re.findall(\"[?]\", text))\n",
    "        text = text.replace(\",\", \" \").replace(\".\", \" \")   \n",
    "        text = re.sub(u'[^a-zа-я0-9]', ' ', text.lower())\n",
    "    \n",
    "    digitsCount = len(re.findall(\"[0-9]+\", text))\n",
    "    wordCount = 0.0\n",
    "    charCount = 0.0\n",
    "    rusCharCount = 0.0\n",
    "    engCharCount = 0.0\n",
    "    \n",
    "    for w in text.split():\n",
    "        if len(w)>1:\n",
    "            wordCount += 1\n",
    "            c, rus, eng = getWordCharCount(w)\n",
    "            charCount += c\n",
    "            rusCharCount += rus\n",
    "            engCharCount += eng\n",
    "    \n",
    "    wordPerSentence = 0.0\n",
    "    charPerSentence = 0.0\n",
    "    rusCharPerSentence = 0.0\n",
    "    engCharPerSentence = 0.0\n",
    "    numCharPerSentence = 0.0\n",
    "    \n",
    "    if not text_processed :\n",
    "        # per sentence\n",
    "        wordPerSentence = tryDivide(wordCount, sentenceCount)\n",
    "        charPerSentence = tryDivide(charCount, sentenceCount)\n",
    "        rusCharPerSentence = tryDivide(rusCharCount, sentenceCount)\n",
    "        engCharPerSentence = tryDivide(engCharCount, sentenceCount)\n",
    "        numCharPerSentence = tryDivide(digitsCount, sentenceCount)\n",
    "    \n",
    "    # per word\n",
    "    charPerWord = tryDivide(charCount, wordCount)\n",
    "    rusCharPerWord = tryDivide(rusCharCount, wordCount)\n",
    "    engCharPerWord = tryDivide(engCharCount, wordCount)\n",
    "    numCharPerWord = tryDivide(digitsCount, wordCount)\n",
    "    \n",
    "    # ratio\n",
    "    rusCharRatio = tryDivide(rusCharCount, charCount)\n",
    "    engCharRatio = tryDivide(engCharCount, charCount)\n",
    "    rusCharVsEngChar = tryDivide(rusCharCount, engCharCount)\n",
    "    engCharVsRusChar = tryDivide(engCharCount, rusCharCount)\n",
    "    numCharVsRusChar = tryDivide(digitsCount, rusCharCount)\n",
    "    numCharVsEngChar = tryDivide(digitsCount, engCharCount)\n",
    "    \n",
    "    stats = {\n",
    "        \"wordCount\" : wordCount,\n",
    "        \"charCount\" : charCount,\n",
    "        \"rusCharCount\" : rusCharCount,\n",
    "        \"engCharCount\" : engCharCount,\n",
    "        \"digitsCount\" : digitsCount     ,\n",
    "        \"charPerWord\" : charPerWord,\n",
    "        \"rusCharPerWord\" : rusCharPerWord,\n",
    "        \"engCharPerWord\" : engCharPerWord,\n",
    "        \"numCharPerWord\" : numCharPerWord,\n",
    "        \"rusCharRatio\" : rusCharRatio,\n",
    "        \"engCharRatio\" : engCharRatio,\n",
    "        \"rusCharVsEngChar\" : rusCharVsEngChar,\n",
    "        \"engCharVsRusChar\" : engCharVsRusChar,\n",
    "        \"numCharVsRusChar\" : numCharVsRusChar,\n",
    "        \"numCharVsEngChar\" : numCharVsEngChar\n",
    "    }\n",
    "    \n",
    "    if not text_processed:\n",
    "        stats.update({\n",
    "        \"sentenceCount\" : sentenceCount,\n",
    "        \"exclamationMarkCount\" : exclamationMarkCount,\n",
    "        \"questionMarkCount\" : questionMarkCount,\n",
    "        \"wordPerSentence\" : wordPerSentence,\n",
    "        \"charPerSentence\" : charPerSentence,\n",
    "        \"rusCharPerSentence\" : rusCharPerSentence,\n",
    "        \"engCharPerSentence\" : engCharPerSentence,\n",
    "        \"numCharPerSentence\" : numCharPerSentence\n",
    "        })\n",
    "\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['itemID', 'attrsJSON', 'attrsJSON_titles', 'attrsJSON_description'], dtype='object')\n",
      "(1315205, 4)\n"
     ]
    }
   ],
   "source": [
    "ItemInfo = pd.read_hdf(FOLDER+\"ItemInfo_\"+CORPUS+\"_\"+FEATURE+\"_processed.h\")\n",
    "ItemInfo[FEATURE].fillna(\"\", inplace=True)\n",
    "print(ItemInfo.columns)\n",
    "print(ItemInfo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed docs : 0\n",
      "Processed docs : 100000\n",
      "Processed docs : 200000\n",
      "Processed docs : 300000\n",
      "Processed docs : 400000\n",
      "Processed docs : 500000\n",
      "Processed docs : 600000\n",
      "Processed docs : 700000\n",
      "Processed docs : 800000\n",
      "Processed docs : 900000\n",
      "Processed docs : 1000000\n",
      "Processed docs : 1100000\n",
      "Processed docs : 1200000\n",
      "Processed docs : 1300000\n",
      "Converting new features to dataframe\n",
      "Storing results\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "FEATURE = \"attrsJSON_description\"\n",
    "\n",
    "stats = []\n",
    "for index, row in ItemInfo.iterrows():\n",
    "    if index % 100000 == 0:\n",
    "        print(\"Processed docs :\",index)\n",
    "    stats.append(getTextStatsFeat(row[FEATURE], text_processed = True))\n",
    "\n",
    "del ItemInfo\n",
    "gc.collect()\n",
    "\n",
    "print(\"Converting new features to dataframe\")\n",
    "pd_stats = pd.DataFrame.from_records(stats)\n",
    "\n",
    "del stats\n",
    "gc.collect()\n",
    "\n",
    "print(\"Storing results\")\n",
    "pickle.dump(pd_stats, open(FOLDER+\"ItemInfo_\"+CORPUS+\"_\"+FEATURE+\"_processed_dumy_features.p\", \"wb\"))\n",
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
