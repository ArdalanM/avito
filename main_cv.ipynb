{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Evgeny'\n",
    "\n",
    "FOLDER = \"/home/evgeny/kaggle/input/\"\n",
    "SAVE_FOLDER = FOLDER + \"/diclogs/\"\n",
    "\n",
    "import theano.sandbox.cuda\n",
    "\n",
    "theano.sandbox.cuda.use(\"cpu\")\n",
    "\n",
    "import os, zipfile, pickle, operator, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from xgboost import XGBModel\n",
    "from sklearn import *\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import core\n",
    "\n",
    "from ml_metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CVutils():\n",
    "    def reshapePrediction(self, y):\n",
    "\n",
    "        assert type(y) == list or type(y) == np.ndarray\n",
    "\n",
    "        if type(y) == list:\n",
    "            y = np.array(y)\n",
    "        else:\n",
    "            if len(y.shape) > 1:\n",
    "                if y.shape[1] == 1: y = y[:, 0]\n",
    "                if y.shape[1] == 2: y = y[:, 1]\n",
    "\n",
    "        y = self._clipProba(y)\n",
    "        return y\n",
    "\n",
    "    def printResults(self, dic_logs):\n",
    "        l_train_logloss = dic_logs['train_error']\n",
    "        l_val_logloss = dic_logs['val_error']\n",
    "\n",
    "        string = (\"{0:.4f}-{1:.4f}\".format(np.mean(l_train_logloss), np.mean(l_val_logloss)))\n",
    "        return string\n",
    "\n",
    "    def dumpPickleSecure(self, dic_logs, filename):\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            print('file exist !')\n",
    "            raise BrokenPipeError\n",
    "        else:\n",
    "            pickle.dump(dic_logs, open(filename, 'wb'))\n",
    "        return\n",
    "\n",
    "    def confusion_matrix(self, y_true, y_pred):\n",
    "\n",
    "        return metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    def eval_func(self, ytrue, ypredproba):\n",
    "\n",
    "        # ytrue = np_utils.to_categorical(ytrue, 2)\n",
    "        return auc(ytrue, ypredproba)\n",
    "\n",
    "    def xgb_eval_func(self, ypred, dtrain):\n",
    "        ytrue = dtrain.get_label().astype(int)\n",
    "        ypred = self._clipProba(ypred)\n",
    "        return 'auc', -self.eval_func(ytrue, ypred)\n",
    "\n",
    "    def _clipProba(self, ypredproba):\n",
    "        \"\"\"\n",
    "        Taking list of proba and returning a list of clipped proba\n",
    "        :param ypredproba:\n",
    "        :return: ypredproba clipped\n",
    "        \"\"\"\"\"\n",
    "\n",
    "        ypredproba = np.where(ypredproba <= 0., 0 + 1e-5, ypredproba)\n",
    "        ypredproba = np.where(ypredproba >= 1., 1 - 1e-5, ypredproba)\n",
    "\n",
    "        return ypredproba\n",
    "\n",
    "    def saveDicLogs(self, dic_logs, filename):\n",
    "        try:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(dic_logs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LoadingDatasets():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def loadFileinZipFile(self, zip_filename, dtypes=None, parsedate=None, password=None, **kvargs):\n",
    "        \"\"\"\n",
    "        Load file to dataframe.\n",
    "        \"\"\"\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as myzip:\n",
    "            if password:\n",
    "                myzip.setpassword(password)\n",
    "\n",
    "            inside_zip_filename = myzip.filelist[0].filename\n",
    "\n",
    "            if parsedate:\n",
    "                pd_data = pd.read_csv(myzip.open(inside_zip_filename), sep=',', parse_dates=parsedate, dtype=dtypes,\n",
    "                                      **kvargs)\n",
    "            else:\n",
    "                pd_data = pd.read_csv(myzip.open(inside_zip_filename), sep=',', dtype=dtypes, **kvargs)\n",
    "            return pd_data, inside_zip_filename\n",
    "\n",
    "    def LoadParseData(self, filename):\n",
    "\n",
    "        data_name = filename.split('.')[0]\n",
    "        pd_data = pd.read_hdf(FOLDER + filename)\n",
    "        cols_features = pd_data.drop(['isDuplicate', 'id'], 1).columns.tolist()\n",
    "\n",
    "        pd_train = pd_data[pd_data['isDuplicate'] >= 0]\n",
    "        pd_test = pd_data[pd_data['isDuplicate'].isnull()]\n",
    "\n",
    "        Y = pd_train['isDuplicate'].values.astype(int)\n",
    "        test_idx = pd_test['id'].values.astype(int)\n",
    "\n",
    "        X = np.array(pd_train.drop(['isDuplicate', 'id'], 1))\n",
    "        X_test = np.array(pd_test.drop(['isDuplicate', 'id'], 1))\n",
    "\n",
    "        return X, Y, X_test, test_idx, pd_data, data_name, cols_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class genericSKLCLF():\n",
    "    def fit_cv(self, X, y, eval_set=()):\n",
    "        return self.fit(X, y)\n",
    "\n",
    "    def get_best_epoch(self):\n",
    "        pass\n",
    "\n",
    "    def get_best_val_metric(self):\n",
    "        pass\n",
    "\n",
    "    def get_FI(self, list_feat):\n",
    "        pass\n",
    "\n",
    "    def _int_to_string(self, number):\n",
    "\n",
    "        if number > 1e6:\n",
    "            output_string = \"{}Mp\".format(int(np.ceil(number / 1e6)))\n",
    "        elif number > 1e3:\n",
    "            output_string = \"{}kp\".format(int(np.ceil(number / 1e3)))\n",
    "        else:\n",
    "            output_string = \"{}p\".format(number)\n",
    "        return output_string\n",
    "\n",
    "    def get_string_params(self):\n",
    "        pass\n",
    "\n",
    "class genericSKLTree(genericSKLCLF):\n",
    "    def fit_cv(self, X, y, eval_set=(), class_weight=None):\n",
    "        return self.fit(X, y, sample_weight=class_weight)\n",
    "\n",
    "    def get_string_params(self):\n",
    "        clf_name = self.base_estimator.__class__.__name__\n",
    "\n",
    "        added_params = [\"_{}\".format(clf_name[:3]),\n",
    "                        \"_{}\".format(self.criterion[:3]),\n",
    "                        \"_md{}\".format(self.max_depth),\n",
    "                        \"_mf{}\".format(self.max_features),\n",
    "                        \"_est{}\".format(self.n_estimators)]\n",
    "        return \"\".join(added_params)\n",
    "\n",
    "    def get_FI(self, list_feats):\n",
    "        importance = [(name, score) for name, score in zip(list_feats, self.feature_importances_)]\n",
    "        importance = sorted(importance, key=operator.itemgetter(1), reverse=True)\n",
    "        return pd.DataFrame(importance)\n",
    "\n",
    "    def get_best_epoch(self):\n",
    "        pass\n",
    "\n",
    "    def get_best_val_metric(self):\n",
    "        pass\n",
    "\n",
    "class genericKerasCLF(genericSKLCLF):\n",
    "    def __init__(self, batch_size=128, nb_epoch=2, verbose=1, callbacks=None,\n",
    "                 shuffle=True, metrics=None, class_weight=None, rebuild=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.shuffle = shuffle\n",
    "        self.metrics = metrics\n",
    "        self.rebuild = rebuild\n",
    "\n",
    "        self.input_dim = None\n",
    "        self.input_length = None\n",
    "\n",
    "        self.model = None\n",
    "        self.logs = None\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def _set_input_dim(self, X, y, eval_set=()):\n",
    "\n",
    "        assert len(X.shape) == 2 or len(X.shape) == 3\n",
    "\n",
    "        if len(X.shape) == 3:\n",
    "            # means we have a sequence\n",
    "            self.input_dim = X.shape[2]\n",
    "            self.input_length = X.shape[1]\n",
    "        else:\n",
    "            # means we have vectors\n",
    "            self.input_dim = X.shape[1]\n",
    "            # handling sparse input\n",
    "            if type(X).__name__ == \"csr_matrix\":\n",
    "                eval_set = (eval_set[0].toarray(), eval_set[1])\n",
    "                X = X.toarray()\n",
    "\n",
    "        # handling multicolumn label\n",
    "        y = np_utils.to_categorical(y, len(np.unique(y)))\n",
    "        eval_set = (eval_set[0], np_utils.to_categorical(eval_set[1], len(np.unique(eval_set[1]))))\n",
    "        return X, y, eval_set\n",
    "\n",
    "    def build_model(self):\n",
    "        pass\n",
    "\n",
    "    def fit_cv(self, X, y, eval_set=()):\n",
    "\n",
    "        X, y, eval_set = self._set_input_dim(X, y, eval_set)\n",
    "\n",
    "        if self.rebuild:\n",
    "            self.model = self.build_model()\n",
    "        if len(eval_set) > 0:\n",
    "            logs = self.model.fit(X, y, batch_size=self.batch_size, nb_epoch=self.nb_epoch,\n",
    "                                  validation_data=(eval_set[0], eval_set[1]),\n",
    "                                  verbose=self.verbose, shuffle=self.shuffle,\n",
    "                                  callbacks=copy.deepcopy(self.callbacks),\n",
    "                                  class_weight=self.class_weight)\n",
    "        else:\n",
    "            logs = self.model.fit(X, y, batch_size=self.batch_size, nb_epoch=self.nb_epoch,\n",
    "                                  verbose=self.verbose, shuffle=self.shuffle,\n",
    "                                  callbacks=copy.deepcopy(self.callbacks), class_weight=self.class_weight)\n",
    "\n",
    "        self.logs = logs\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if type(X).__name__ == \"csr_matrix\":\n",
    "            X = X.toarray()\n",
    "\n",
    "        prediction = self.model.predict_proba(X, verbose=False)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_config()\n",
    "\n",
    "    def get_best_epoch(self):\n",
    "        return np.argmin(self.logs.history['val_loss'])\n",
    "\n",
    "    def get_best_val_metric(self):\n",
    "        return np.min(self.logs.history['val_loss'])\n",
    "\n",
    "    def keras_class_weight(self, Y_vec):\n",
    "        # Find the weight of each class as present in y.\n",
    "        # inversely proportional to the number of samples in the class\n",
    "        recip_freq = 1. / np.bincount(Y_vec)\n",
    "        weight = recip_freq / np.mean(recip_freq)\n",
    "        dic_w = {index: weight_value for index, weight_value in enumerate(weight)}\n",
    "        return dic_w\n",
    "\n",
    "    def get_num_params(self):\n",
    "        # Compute number of params in a model (the actual number of floats)\n",
    "        return sum([np.prod(K.get_value(w).shape) for w in self.model.trainable_weights])\n",
    "\n",
    "class genericXGB(genericSKLCLF):\n",
    "    def __init__(self, eval_metric=\"logloss\", early_stopping_rounds=300, verbose=True,\n",
    "                 max_depth=3, learning_rate=0.1,\n",
    "                 n_estimators=100, silent=True,\n",
    "                 objective=\"binary:logistic\",\n",
    "                 nthread=-1, gamma=0, min_child_weight=1,\n",
    "                 max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1,\n",
    "                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "                 base_score=0.5, seed=0, missing=None):\n",
    "\n",
    "        self.eval_metric = eval_metric\n",
    "        self.esr = early_stopping_rounds\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.model = XGBModel(max_depth, learning_rate,\n",
    "                              n_estimators, silent, objective,\n",
    "                              nthread, gamma, min_child_weight,\n",
    "                              max_delta_step, subsample,\n",
    "                              colsample_bytree, colsample_bylevel,\n",
    "                              reg_alpha, reg_lambda,\n",
    "                              scale_pos_weight, base_score, seed, missing)\n",
    "\n",
    "    def fit_cv(self, X, y, eval_set=(), class_weight=None):\n",
    "\n",
    "        if len(eval_set) > 0:\n",
    "            self.model.fit(X, y, eval_set=[eval_set], eval_metric=self.eval_metric,\n",
    "                           early_stopping_rounds=self.esr, verbose=self.verbose)\n",
    "        else:\n",
    "            self.model.fit(X, y, verbose=self.verbose)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        preds = self.model.predict(X, ntree_limit=self.model.best_ntree_limit)\n",
    "        return preds\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        preds = self.model.predict(X, ntree_limit=self.model.best_ntree_limit)\n",
    "        return preds\n",
    "\n",
    "    def get_string_params(self):\n",
    "        added_params = [\"_{}\".format('-'.join(list(map(lambda x: x[:3], self.model.objective.split(':'))))),\n",
    "                        \"_md{}\".format(self.model.max_depth),\n",
    "                        \"_lr{}\".format(self.model.learning_rate),\n",
    "                        \"_csb{}\".format(self.model.colsample_bytree),\n",
    "                        \"_esr{}\".format(self.esr),\n",
    "                        \"_est{}\".format(self.model.n_estimators)]\n",
    "        return \"\".join(added_params)\n",
    "\n",
    "    def get_FI(self, col_features):\n",
    "\n",
    "        dic_fi = self.model._Booster.get_fscore()\n",
    "\n",
    "        # getting somithing like [(f0, score), (f1, score)]\n",
    "        importance = [(col_features[int(key[1:])], dic_fi[key]) for key in dic_fi]\n",
    "\n",
    "        # same but sorted by score\n",
    "        importance = sorted(importance, key=operator.itemgetter(1), reverse=True)\n",
    "        sum_importance = np.sum([score for feat, score in importance])\n",
    "        importance = [(name, score / sum_importance) for name, score in importance]\n",
    "\n",
    "        return pd.DataFrame(importance)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "\n",
    "    def get_best_epoch(self):\n",
    "        return self.model.best_iteration\n",
    "\n",
    "    def get_best_val_metric(self):\n",
    "        return self.model.best_score\n",
    "\n",
    "\n",
    "class RFcla(genericSKLTree, ensemble.RandomForestClassifier):\n",
    "    pass\n",
    "class RFreg(genericSKLTree, ensemble.RandomForestRegressor):\n",
    "    pass\n",
    "class ETcla(genericSKLTree, ensemble.ExtraTreesClassifier):\n",
    "    pass\n",
    "class ETreg(genericSKLTree, ensemble.ExtraTreesRegressor):\n",
    "    pass\n",
    "class CAL(genericSKLTree, calibration.CalibratedClassifierCV):\n",
    "    def get_string_params(self):\n",
    "        # sub_clf = self.base_estimator\n",
    "        sub_clf_name = self.base_estimator.__class__.__name__\n",
    "\n",
    "        added_params = [\"_{}\".format(sub_clf_name[:3]),\n",
    "                        \"_{}\".format(self.method[:3]),\n",
    "                        \"_{}\".format(self.base_estimator.criterion[:3]),\n",
    "                        \"_md{}\".format(self.base_estimator.max_depth),\n",
    "                        \"_mf{}\".format(self.base_estimator.max_features),\n",
    "                        \"_est{}\".format(self.base_estimator.n_estimators)]\n",
    "        return \"\".join(added_params)\n",
    "\n",
    "    def get_FI(self, list_feats):\n",
    "        pass\n",
    "class LR(genericSKLCLF, linear_model.LogisticRegression):\n",
    "    def get_string_params(self):\n",
    "        clf_name = self.__class__.__name__\n",
    "\n",
    "        added_params = [\"_{}\".format(clf_name[:3]),\n",
    "                        \"_{}\".format(self.penalty),\n",
    "                        \"_C{}\".format(self.C),\n",
    "                        \"_mi{}\".format(self.max_iter)]\n",
    "        return \"\".join(added_params)\n",
    "class XGB(genericXGB):\n",
    "    def __repr__(self):\n",
    "        return str(self.get_params())\n",
    "class MLP(genericKerasCLF):\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(core.Dense(128, init='normal', input_shape=(self.input_dim,),\n",
    "                             W_regularizer=None))\n",
    "        model.add(core.Dropout(0.1))\n",
    "        model.add(core.Activation('relu'))\n",
    "        model.add(core.Dense(128, init='normal', W_regularizer=None))\n",
    "        model.add(core.Dropout(0.1))\n",
    "        model.add(core.Activation('relu'))\n",
    "        model.add(core.Dense(2))\n",
    "        model.add(core.Activation('softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.SGD(lr=.001, momentum=0.9, decay=0.0001),\n",
    "                      metrics=self.metrics)\n",
    "        return model\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"mlp\"\n",
    "\n",
    "    def get_string_params(self):\n",
    "        l_layers_params = self.model.get_config()\n",
    "\n",
    "        nb_params = self.get_num_params()\n",
    "        nb_params_string = self._int_to_string(nb_params)\n",
    "\n",
    "        added_params = [\"{}_\".format(nb_params_string)]\n",
    "        #\n",
    "        for i, layer in enumerate(l_layers_params[:-2]):\n",
    "\n",
    "            if \"Dense\" in layer['class_name']:\n",
    "                nb_neurons = layer['config']['output_dim']\n",
    "                added_params.append(\"D{}\".format(nb_neurons))\n",
    "\n",
    "        added_params.append(\"_cw{}-{}\".format(self.class_weight[0], self.class_weight[1]))\n",
    "\n",
    "        return \"\".join(added_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General params\n",
    "STORE = True\n",
    "n_folds = 2\n",
    "nthread = 8\n",
    "model_seed = 456\n",
    "cv_seed = 123\n",
    "\n",
    "\n",
    "X, Y, X_test, test_idx, pd_data, data_name, col_feats = LoadingDatasets().LoadParseData('D1_20may.p')\n",
    "D0 = (X, Y, X_test, test_idx, data_name, col_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indice = 2393116\n",
    "# xtrain = X[:indice]\n",
    "# ytrain = Y[:indice]\n",
    "# xtest = X[indice+1:]\n",
    "# ytest = Y[indice+1:]\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# clf = XGBClassifier(max_depth=8, learning_rate=0.1, n_estimators=1000, objective=\"binary:logistic\",\n",
    "#                     nthread=nthread, seed=model_seed)\n",
    "\n",
    "# clf.fit(xtrain, ytrain, eval_set=[(xtest, ytest)], eval_metric='auc', early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generic_tree_params = {'n_jobs': nthread, 'random_state': model_seed, 'n_estimators': 200}\n",
    "\n",
    "tree_cla1 = {'max_features': 50, 'criterion': 'entropy', 'max_depth': 5, 'class_weight': 'balanced'}\n",
    "tree_cla1.update(generic_tree_params)\n",
    "\n",
    "tree_reg1 = {'max_features': 50, 'criterion': 'mse', 'max_depth': 5}\n",
    "tree_reg1.update(generic_tree_params)\n",
    "\n",
    "generic_xgb_params = {'n_estimators': 1000, 'nthread': nthread,\n",
    "                      'seed': model_seed, 'early_stopping_rounds': 100, 'verbose': True}\n",
    "\n",
    "xgb_reg1 = {'objective': 'reg:linear', 'max_depth': 5,\n",
    "            'learning_rate': 0.01}\n",
    "xgb_reg1.update(generic_xgb_params)\n",
    "\n",
    "xgb_cla1 = {'objective': 'binary:logistic', 'max_depth': 8,\n",
    "            'learning_rate': 0.2, 'subsample': 0.9}\n",
    "xgb_cla1.update(generic_xgb_params)\n",
    "\n",
    "xgb_cla2 = {'objective': 'binary:logistic', 'max_depth': 7,\n",
    "            'learning_rate': 0.01}\n",
    "xgb_cla2.update(generic_xgb_params)\n",
    "\n",
    "xgb_poi1 = {'objective': 'count:poisson', 'max_depth': 5,\n",
    "            'learning_rate': 0.01}\n",
    "xgb_poi1.update(generic_xgb_params)\n",
    "\n",
    "utils = CVutils()\n",
    "\n",
    "\n",
    "def lr_function(epoch):\n",
    "    initial_lr = 0.01\n",
    "    coef = (int(epoch / 10) + 1)\n",
    "    return initial_lr / coef\n",
    "\n",
    "\n",
    "params_mlp = {'batch_size': 256, 'nb_epoch': 30, 'verbose': 2, 'metrics': [\"accuracy\"],\n",
    "              'callbacks': [\n",
    "                  # callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min'),\n",
    "                  # callbacks.LearningRateScheduler(lr_function),\n",
    "              ],\n",
    "              'shuffle': True, 'rebuild': True}\n",
    "\n",
    "clfs = [\n",
    "    # (D2, MLP(class_weight={0: 1, 1: 30}, **params_mlp)),\n",
    "\n",
    "    (D0, XGB(eval_metric=utils.xgb_eval_func, **xgb_cla1),\n",
    "    cross_validation.StratifiedShuffleSplit(D0[1], n_iter=2, test_size=0.2, train_size=None, random_state=cv_seed)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Classifier [0]\n",
      "{'colsample_bylevel': 1, 'colsample_bytree': 1, 'silent': True, 'missing': None, 'objective': 'binary:logistic', 'gamma': 0, 'min_child_weight': 1, 'n_estimators': 1000, 'reg_lambda': 1, 'max_delta_step': 0, 'seed': 456, 'subsample': 0.9, 'learning_rate': 0.2, 'scale_pos_weight': 1, 'max_depth': 8, 'base_score': 0.5, 'reg_alpha': 0, 'nthread': 8}\n",
      "Fold [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_0 error hasn't decreased in 100 rounds.\n",
      "[0]\tvalidation_0-auc:-0.784385\n",
      "[1]\tvalidation_0-auc:-0.788956\n",
      "[2]\tvalidation_0-auc:-0.792267\n",
      "[3]\tvalidation_0-auc:-0.794311\n",
      "[4]\tvalidation_0-auc:-0.797089\n",
      "[5]\tvalidation_0-auc:-0.798666\n",
      "[6]\tvalidation_0-auc:-0.799856\n",
      "[7]\tvalidation_0-auc:-0.800943\n",
      "[8]\tvalidation_0-auc:-0.802118\n",
      "[9]\tvalidation_0-auc:-0.803795\n",
      "[10]\tvalidation_0-auc:-0.804403\n",
      "[11]\tvalidation_0-auc:-0.805078\n",
      "[12]\tvalidation_0-auc:-0.805384\n",
      "[13]\tvalidation_0-auc:-0.806168\n",
      "[14]\tvalidation_0-auc:-0.807183\n",
      "[15]\tvalidation_0-auc:-0.807979\n",
      "[16]\tvalidation_0-auc:-0.808589\n",
      "[17]\tvalidation_0-auc:-0.809327\n",
      "[18]\tvalidation_0-auc:-0.809739\n",
      "[19]\tvalidation_0-auc:-0.810001\n",
      "[20]\tvalidation_0-auc:-0.810389\n",
      "[21]\tvalidation_0-auc:-0.810849\n",
      "[22]\tvalidation_0-auc:-0.811572\n",
      "[23]\tvalidation_0-auc:-0.811990\n",
      "[24]\tvalidation_0-auc:-0.812351\n",
      "[25]\tvalidation_0-auc:-0.812830\n",
      "[26]\tvalidation_0-auc:-0.812996\n",
      "[27]\tvalidation_0-auc:-0.813185\n",
      "[28]\tvalidation_0-auc:-0.813508\n",
      "[29]\tvalidation_0-auc:-0.813944\n",
      "[30]\tvalidation_0-auc:-0.814207\n",
      "[31]\tvalidation_0-auc:-0.814424\n",
      "[32]\tvalidation_0-auc:-0.814814\n",
      "[33]\tvalidation_0-auc:-0.815003\n",
      "[34]\tvalidation_0-auc:-0.815126\n",
      "[35]\tvalidation_0-auc:-0.815340\n",
      "[36]\tvalidation_0-auc:-0.815347\n",
      "[37]\tvalidation_0-auc:-0.815613\n",
      "[38]\tvalidation_0-auc:-0.815761\n",
      "[39]\tvalidation_0-auc:-0.816111\n",
      "[40]\tvalidation_0-auc:-0.816220\n",
      "[41]\tvalidation_0-auc:-0.816302\n",
      "[42]\tvalidation_0-auc:-0.816548\n",
      "[43]\tvalidation_0-auc:-0.816935\n",
      "[44]\tvalidation_0-auc:-0.817010\n",
      "[45]\tvalidation_0-auc:-0.817049\n",
      "[46]\tvalidation_0-auc:-0.817149\n",
      "[47]\tvalidation_0-auc:-0.817431\n",
      "[48]\tvalidation_0-auc:-0.817467\n",
      "[49]\tvalidation_0-auc:-0.817595\n",
      "[50]\tvalidation_0-auc:-0.817702\n",
      "[51]\tvalidation_0-auc:-0.817800\n",
      "[52]\tvalidation_0-auc:-0.817863\n",
      "[53]\tvalidation_0-auc:-0.817960\n",
      "[54]\tvalidation_0-auc:-0.818123\n",
      "[55]\tvalidation_0-auc:-0.818258\n",
      "[56]\tvalidation_0-auc:-0.818470\n",
      "[57]\tvalidation_0-auc:-0.818598\n",
      "[58]\tvalidation_0-auc:-0.818685\n",
      "[59]\tvalidation_0-auc:-0.818708\n",
      "[60]\tvalidation_0-auc:-0.818761\n",
      "[61]\tvalidation_0-auc:-0.818886\n",
      "[62]\tvalidation_0-auc:-0.818936\n",
      "[63]\tvalidation_0-auc:-0.819049\n",
      "[64]\tvalidation_0-auc:-0.819076\n",
      "[65]\tvalidation_0-auc:-0.819105\n",
      "[66]\tvalidation_0-auc:-0.819125\n",
      "[67]\tvalidation_0-auc:-0.819206\n",
      "[68]\tvalidation_0-auc:-0.819416\n",
      "[69]\tvalidation_0-auc:-0.819573\n",
      "[70]\tvalidation_0-auc:-0.819626\n",
      "[71]\tvalidation_0-auc:-0.819658\n",
      "[72]\tvalidation_0-auc:-0.819675\n",
      "[73]\tvalidation_0-auc:-0.819752\n",
      "[74]\tvalidation_0-auc:-0.819781\n",
      "[75]\tvalidation_0-auc:-0.819847\n",
      "[76]\tvalidation_0-auc:-0.819875\n",
      "[77]\tvalidation_0-auc:-0.819998\n",
      "[78]\tvalidation_0-auc:-0.820102\n",
      "[79]\tvalidation_0-auc:-0.820154\n",
      "[80]\tvalidation_0-auc:-0.820193\n",
      "[81]\tvalidation_0-auc:-0.820228\n",
      "[82]\tvalidation_0-auc:-0.820298\n",
      "[83]\tvalidation_0-auc:-0.820338\n",
      "[84]\tvalidation_0-auc:-0.820432\n",
      "[85]\tvalidation_0-auc:-0.820520\n",
      "[86]\tvalidation_0-auc:-0.820640\n",
      "[87]\tvalidation_0-auc:-0.820785\n",
      "[88]\tvalidation_0-auc:-0.820802\n",
      "[89]\tvalidation_0-auc:-0.820814\n",
      "[90]\tvalidation_0-auc:-0.820895\n",
      "[91]\tvalidation_0-auc:-0.821005\n",
      "[92]\tvalidation_0-auc:-0.821034\n",
      "[93]\tvalidation_0-auc:-0.821004\n",
      "[94]\tvalidation_0-auc:-0.821061\n",
      "[95]\tvalidation_0-auc:-0.821126\n",
      "[96]\tvalidation_0-auc:-0.821169\n",
      "[97]\tvalidation_0-auc:-0.821175\n",
      "[98]\tvalidation_0-auc:-0.821256\n",
      "[99]\tvalidation_0-auc:-0.821429\n",
      "[100]\tvalidation_0-auc:-0.821538\n",
      "[101]\tvalidation_0-auc:-0.821559\n",
      "[102]\tvalidation_0-auc:-0.821623\n",
      "[103]\tvalidation_0-auc:-0.821657\n",
      "[104]\tvalidation_0-auc:-0.821732\n",
      "[105]\tvalidation_0-auc:-0.821755\n",
      "[106]\tvalidation_0-auc:-0.821737\n",
      "[107]\tvalidation_0-auc:-0.821765\n",
      "[108]\tvalidation_0-auc:-0.821833\n",
      "[109]\tvalidation_0-auc:-0.821852\n",
      "[110]\tvalidation_0-auc:-0.821853\n",
      "[111]\tvalidation_0-auc:-0.821903\n",
      "[112]\tvalidation_0-auc:-0.821951\n",
      "[113]\tvalidation_0-auc:-0.821960\n",
      "[114]\tvalidation_0-auc:-0.822024\n",
      "[115]\tvalidation_0-auc:-0.822041\n",
      "[116]\tvalidation_0-auc:-0.822046\n",
      "[117]\tvalidation_0-auc:-0.822065\n",
      "[118]\tvalidation_0-auc:-0.822077\n",
      "[119]\tvalidation_0-auc:-0.822098\n",
      "[120]\tvalidation_0-auc:-0.822132\n",
      "[121]\tvalidation_0-auc:-0.822130\n",
      "[122]\tvalidation_0-auc:-0.822201\n",
      "[123]\tvalidation_0-auc:-0.822263\n",
      "[124]\tvalidation_0-auc:-0.822269\n",
      "[125]\tvalidation_0-auc:-0.822279\n",
      "[126]\tvalidation_0-auc:-0.822321\n",
      "[127]\tvalidation_0-auc:-0.822378\n",
      "[128]\tvalidation_0-auc:-0.822406\n",
      "[129]\tvalidation_0-auc:-0.822440\n",
      "[130]\tvalidation_0-auc:-0.822457\n",
      "[131]\tvalidation_0-auc:-0.822475\n",
      "[132]\tvalidation_0-auc:-0.822475\n",
      "[133]\tvalidation_0-auc:-0.822483\n",
      "[134]\tvalidation_0-auc:-0.822495\n",
      "[135]\tvalidation_0-auc:-0.822502\n",
      "[136]\tvalidation_0-auc:-0.822524\n",
      "[137]\tvalidation_0-auc:-0.822581\n",
      "[138]\tvalidation_0-auc:-0.822629\n",
      "[139]\tvalidation_0-auc:-0.822695\n",
      "[140]\tvalidation_0-auc:-0.822705\n",
      "[141]\tvalidation_0-auc:-0.822711\n",
      "[142]\tvalidation_0-auc:-0.822778\n",
      "[143]\tvalidation_0-auc:-0.822844\n",
      "[144]\tvalidation_0-auc:-0.822770\n",
      "[145]\tvalidation_0-auc:-0.822772\n",
      "[146]\tvalidation_0-auc:-0.822775\n",
      "[147]\tvalidation_0-auc:-0.822787\n",
      "[148]\tvalidation_0-auc:-0.822831\n",
      "[149]\tvalidation_0-auc:-0.822878\n",
      "[150]\tvalidation_0-auc:-0.822876\n",
      "[151]\tvalidation_0-auc:-0.822965\n",
      "[152]\tvalidation_0-auc:-0.823018\n",
      "[153]\tvalidation_0-auc:-0.823040\n",
      "[154]\tvalidation_0-auc:-0.823056\n",
      "[155]\tvalidation_0-auc:-0.823092\n",
      "[156]\tvalidation_0-auc:-0.823158\n",
      "[157]\tvalidation_0-auc:-0.823164\n",
      "[158]\tvalidation_0-auc:-0.823179\n",
      "[159]\tvalidation_0-auc:-0.823231\n",
      "[160]\tvalidation_0-auc:-0.823276\n",
      "[161]\tvalidation_0-auc:-0.823397\n",
      "[162]\tvalidation_0-auc:-0.823416\n",
      "[163]\tvalidation_0-auc:-0.823418\n",
      "[164]\tvalidation_0-auc:-0.823442\n",
      "[165]\tvalidation_0-auc:-0.823490\n",
      "[166]\tvalidation_0-auc:-0.823498\n",
      "[167]\tvalidation_0-auc:-0.823494\n",
      "[168]\tvalidation_0-auc:-0.823500\n",
      "[169]\tvalidation_0-auc:-0.823581\n",
      "[170]\tvalidation_0-auc:-0.823547\n",
      "[171]\tvalidation_0-auc:-0.823554\n",
      "[172]\tvalidation_0-auc:-0.823640\n",
      "[173]\tvalidation_0-auc:-0.823678\n",
      "[174]\tvalidation_0-auc:-0.823680\n",
      "[175]\tvalidation_0-auc:-0.823707\n",
      "[176]\tvalidation_0-auc:-0.823702\n",
      "[177]\tvalidation_0-auc:-0.823703\n",
      "[178]\tvalidation_0-auc:-0.823747\n",
      "[179]\tvalidation_0-auc:-0.823768\n",
      "[180]\tvalidation_0-auc:-0.823771\n",
      "[181]\tvalidation_0-auc:-0.823805\n",
      "[182]\tvalidation_0-auc:-0.823826\n",
      "[183]\tvalidation_0-auc:-0.823820\n",
      "[184]\tvalidation_0-auc:-0.823834\n",
      "[185]\tvalidation_0-auc:-0.823842\n",
      "[186]\tvalidation_0-auc:-0.823867\n",
      "[187]\tvalidation_0-auc:-0.823878\n",
      "[188]\tvalidation_0-auc:-0.823965\n",
      "[189]\tvalidation_0-auc:-0.823968\n",
      "[190]\tvalidation_0-auc:-0.823966\n",
      "[191]\tvalidation_0-auc:-0.823978\n",
      "[192]\tvalidation_0-auc:-0.823990\n",
      "[193]\tvalidation_0-auc:-0.823996\n",
      "[194]\tvalidation_0-auc:-0.824008\n",
      "[195]\tvalidation_0-auc:-0.824032\n",
      "[196]\tvalidation_0-auc:-0.824036\n",
      "[197]\tvalidation_0-auc:-0.824039\n",
      "[198]\tvalidation_0-auc:-0.824045\n",
      "[199]\tvalidation_0-auc:-0.824055\n",
      "[200]\tvalidation_0-auc:-0.824055\n",
      "[201]\tvalidation_0-auc:-0.824058\n",
      "[202]\tvalidation_0-auc:-0.824067\n",
      "[203]\tvalidation_0-auc:-0.824082\n",
      "[204]\tvalidation_0-auc:-0.824137\n",
      "[205]\tvalidation_0-auc:-0.824142\n",
      "[206]\tvalidation_0-auc:-0.824148\n",
      "[207]\tvalidation_0-auc:-0.824148\n",
      "[208]\tvalidation_0-auc:-0.824157\n",
      "[209]\tvalidation_0-auc:-0.824182\n",
      "[210]\tvalidation_0-auc:-0.824219\n",
      "[211]\tvalidation_0-auc:-0.824222\n",
      "[212]\tvalidation_0-auc:-0.824232\n",
      "[213]\tvalidation_0-auc:-0.824234\n",
      "[214]\tvalidation_0-auc:-0.824258\n",
      "[215]\tvalidation_0-auc:-0.824256\n",
      "[216]\tvalidation_0-auc:-0.824262\n",
      "[217]\tvalidation_0-auc:-0.824311\n",
      "[218]\tvalidation_0-auc:-0.824313\n",
      "[219]\tvalidation_0-auc:-0.824303\n",
      "[220]\tvalidation_0-auc:-0.824303\n",
      "[221]\tvalidation_0-auc:-0.824309\n",
      "[222]\tvalidation_0-auc:-0.824322\n",
      "[223]\tvalidation_0-auc:-0.824324\n",
      "[224]\tvalidation_0-auc:-0.824331\n",
      "[225]\tvalidation_0-auc:-0.824404\n",
      "[226]\tvalidation_0-auc:-0.824405\n",
      "[227]\tvalidation_0-auc:-0.824411\n",
      "[228]\tvalidation_0-auc:-0.824468\n",
      "[229]\tvalidation_0-auc:-0.824478\n",
      "[230]\tvalidation_0-auc:-0.824537\n",
      "[231]\tvalidation_0-auc:-0.824600\n",
      "[232]\tvalidation_0-auc:-0.824600\n",
      "[233]\tvalidation_0-auc:-0.824627\n",
      "[234]\tvalidation_0-auc:-0.824644\n",
      "[235]\tvalidation_0-auc:-0.824672\n",
      "[236]\tvalidation_0-auc:-0.824689\n",
      "[237]\tvalidation_0-auc:-0.824696\n",
      "[238]\tvalidation_0-auc:-0.824709\n",
      "[239]\tvalidation_0-auc:-0.824716\n",
      "[240]\tvalidation_0-auc:-0.824734\n",
      "[241]\tvalidation_0-auc:-0.824738\n",
      "[242]\tvalidation_0-auc:-0.824818\n",
      "[243]\tvalidation_0-auc:-0.824873\n",
      "[244]\tvalidation_0-auc:-0.824870\n",
      "[245]\tvalidation_0-auc:-0.824877\n",
      "[246]\tvalidation_0-auc:-0.824888\n",
      "[247]\tvalidation_0-auc:-0.824907\n",
      "[248]\tvalidation_0-auc:-0.824934\n",
      "[249]\tvalidation_0-auc:-0.824933\n",
      "[250]\tvalidation_0-auc:-0.824956\n",
      "[251]\tvalidation_0-auc:-0.824956\n",
      "[252]\tvalidation_0-auc:-0.824975\n",
      "[253]\tvalidation_0-auc:-0.824993\n",
      "[254]\tvalidation_0-auc:-0.825013\n",
      "[255]\tvalidation_0-auc:-0.825045\n",
      "[256]\tvalidation_0-auc:-0.825061\n",
      "[257]\tvalidation_0-auc:-0.825076\n",
      "[258]\tvalidation_0-auc:-0.825080\n",
      "[259]\tvalidation_0-auc:-0.825077\n",
      "[260]\tvalidation_0-auc:-0.825100\n",
      "[261]\tvalidation_0-auc:-0.825098\n",
      "[262]\tvalidation_0-auc:-0.825095\n",
      "[263]\tvalidation_0-auc:-0.825104\n",
      "[264]\tvalidation_0-auc:-0.825133\n",
      "[265]\tvalidation_0-auc:-0.825176\n",
      "[266]\tvalidation_0-auc:-0.825170\n",
      "[267]\tvalidation_0-auc:-0.825169\n",
      "[268]\tvalidation_0-auc:-0.825172\n",
      "[269]\tvalidation_0-auc:-0.825203\n",
      "[270]\tvalidation_0-auc:-0.825203\n",
      "[271]\tvalidation_0-auc:-0.825209\n",
      "[272]\tvalidation_0-auc:-0.825221\n",
      "[273]\tvalidation_0-auc:-0.825231\n",
      "[274]\tvalidation_0-auc:-0.825237\n",
      "[275]\tvalidation_0-auc:-0.825249\n",
      "[276]\tvalidation_0-auc:-0.825251\n",
      "[277]\tvalidation_0-auc:-0.825272\n",
      "[278]\tvalidation_0-auc:-0.825293\n",
      "[279]\tvalidation_0-auc:-0.825237\n",
      "[280]\tvalidation_0-auc:-0.825300\n",
      "[281]\tvalidation_0-auc:-0.825299\n",
      "[282]\tvalidation_0-auc:-0.825296\n",
      "[283]\tvalidation_0-auc:-0.825298\n",
      "[284]\tvalidation_0-auc:-0.825303\n",
      "[285]\tvalidation_0-auc:-0.825303\n",
      "[286]\tvalidation_0-auc:-0.825304\n",
      "[287]\tvalidation_0-auc:-0.825308\n",
      "[288]\tvalidation_0-auc:-0.825302\n",
      "[289]\tvalidation_0-auc:-0.825302\n",
      "[290]\tvalidation_0-auc:-0.825308\n",
      "[291]\tvalidation_0-auc:-0.825320\n",
      "[292]\tvalidation_0-auc:-0.825330\n",
      "[293]\tvalidation_0-auc:-0.825336\n",
      "[294]\tvalidation_0-auc:-0.825351\n",
      "[295]\tvalidation_0-auc:-0.825357\n",
      "[296]\tvalidation_0-auc:-0.825372\n",
      "[297]\tvalidation_0-auc:-0.825377\n",
      "[298]\tvalidation_0-auc:-0.825383\n",
      "[299]\tvalidation_0-auc:-0.825388\n",
      "[300]\tvalidation_0-auc:-0.825429\n",
      "[301]\tvalidation_0-auc:-0.825456\n",
      "[302]\tvalidation_0-auc:-0.825466\n",
      "[303]\tvalidation_0-auc:-0.825474\n",
      "[304]\tvalidation_0-auc:-0.825474\n",
      "[305]\tvalidation_0-auc:-0.825516\n",
      "[306]\tvalidation_0-auc:-0.825521\n",
      "[307]\tvalidation_0-auc:-0.825537\n",
      "[308]\tvalidation_0-auc:-0.825545\n",
      "[309]\tvalidation_0-auc:-0.825573\n",
      "[310]\tvalidation_0-auc:-0.825574\n",
      "[311]\tvalidation_0-auc:-0.825587\n",
      "[312]\tvalidation_0-auc:-0.825589\n",
      "[313]\tvalidation_0-auc:-0.825617\n",
      "[314]\tvalidation_0-auc:-0.825614\n",
      "[315]\tvalidation_0-auc:-0.825611\n",
      "[316]\tvalidation_0-auc:-0.825621\n",
      "[317]\tvalidation_0-auc:-0.825654\n",
      "[318]\tvalidation_0-auc:-0.825658\n",
      "[319]\tvalidation_0-auc:-0.825660\n",
      "[320]\tvalidation_0-auc:-0.825669\n",
      "[321]\tvalidation_0-auc:-0.825699\n",
      "[322]\tvalidation_0-auc:-0.825716\n",
      "[323]\tvalidation_0-auc:-0.825752\n",
      "[324]\tvalidation_0-auc:-0.825789\n",
      "[325]\tvalidation_0-auc:-0.825815\n",
      "[326]\tvalidation_0-auc:-0.825821\n",
      "[327]\tvalidation_0-auc:-0.825834\n",
      "[328]\tvalidation_0-auc:-0.825874\n",
      "[329]\tvalidation_0-auc:-0.825882\n",
      "[330]\tvalidation_0-auc:-0.825896\n",
      "[331]\tvalidation_0-auc:-0.825896\n",
      "[332]\tvalidation_0-auc:-0.825908\n",
      "[333]\tvalidation_0-auc:-0.825928\n",
      "[334]\tvalidation_0-auc:-0.825931\n",
      "[335]\tvalidation_0-auc:-0.825957\n",
      "[336]\tvalidation_0-auc:-0.825962\n",
      "[337]\tvalidation_0-auc:-0.825999\n",
      "[338]\tvalidation_0-auc:-0.826000\n",
      "[339]\tvalidation_0-auc:-0.826000\n",
      "[340]\tvalidation_0-auc:-0.826001\n",
      "[341]\tvalidation_0-auc:-0.826027\n",
      "[342]\tvalidation_0-auc:-0.826040\n",
      "[343]\tvalidation_0-auc:-0.826039\n",
      "[344]\tvalidation_0-auc:-0.826049\n",
      "[345]\tvalidation_0-auc:-0.826080\n",
      "[346]\tvalidation_0-auc:-0.826076\n",
      "[347]\tvalidation_0-auc:-0.826078\n",
      "[348]\tvalidation_0-auc:-0.826079\n",
      "[349]\tvalidation_0-auc:-0.826085\n",
      "[350]\tvalidation_0-auc:-0.826087\n",
      "[351]\tvalidation_0-auc:-0.826093\n",
      "[352]\tvalidation_0-auc:-0.826088\n",
      "[353]\tvalidation_0-auc:-0.826091\n",
      "[354]\tvalidation_0-auc:-0.826111\n",
      "[355]\tvalidation_0-auc:-0.826123\n",
      "[356]\tvalidation_0-auc:-0.826168\n",
      "[357]\tvalidation_0-auc:-0.826202\n",
      "[358]\tvalidation_0-auc:-0.826203\n",
      "[359]\tvalidation_0-auc:-0.826206\n",
      "[360]\tvalidation_0-auc:-0.826209\n",
      "[361]\tvalidation_0-auc:-0.826253\n",
      "[362]\tvalidation_0-auc:-0.826265\n",
      "[363]\tvalidation_0-auc:-0.826280\n",
      "[364]\tvalidation_0-auc:-0.826290\n",
      "[365]\tvalidation_0-auc:-0.826291\n",
      "[366]\tvalidation_0-auc:-0.826288\n",
      "[367]\tvalidation_0-auc:-0.826295\n",
      "[368]\tvalidation_0-auc:-0.826297\n",
      "[369]\tvalidation_0-auc:-0.826318\n",
      "[370]\tvalidation_0-auc:-0.826329\n",
      "[371]\tvalidation_0-auc:-0.826344\n",
      "[372]\tvalidation_0-auc:-0.826349\n",
      "[373]\tvalidation_0-auc:-0.826349\n",
      "[374]\tvalidation_0-auc:-0.826352\n",
      "[375]\tvalidation_0-auc:-0.826355\n",
      "[376]\tvalidation_0-auc:-0.826357\n",
      "[377]\tvalidation_0-auc:-0.826319\n",
      "[378]\tvalidation_0-auc:-0.826320\n",
      "[379]\tvalidation_0-auc:-0.826324\n",
      "[380]\tvalidation_0-auc:-0.826333\n",
      "[381]\tvalidation_0-auc:-0.826354\n",
      "[382]\tvalidation_0-auc:-0.826362\n",
      "[383]\tvalidation_0-auc:-0.826369\n",
      "[384]\tvalidation_0-auc:-0.826377\n",
      "[385]\tvalidation_0-auc:-0.826375\n",
      "[386]\tvalidation_0-auc:-0.826391\n",
      "[387]\tvalidation_0-auc:-0.826393\n",
      "[388]\tvalidation_0-auc:-0.826400\n",
      "[389]\tvalidation_0-auc:-0.826400\n",
      "[390]\tvalidation_0-auc:-0.826398\n",
      "[391]\tvalidation_0-auc:-0.826414\n",
      "[392]\tvalidation_0-auc:-0.826410\n",
      "[393]\tvalidation_0-auc:-0.826420\n",
      "[394]\tvalidation_0-auc:-0.826421\n",
      "[395]\tvalidation_0-auc:-0.826419\n",
      "[396]\tvalidation_0-auc:-0.826418\n",
      "[397]\tvalidation_0-auc:-0.826418\n",
      "[398]\tvalidation_0-auc:-0.826438\n",
      "[399]\tvalidation_0-auc:-0.826443\n",
      "[400]\tvalidation_0-auc:-0.826468\n",
      "[401]\tvalidation_0-auc:-0.826485\n",
      "[402]\tvalidation_0-auc:-0.826493\n",
      "[403]\tvalidation_0-auc:-0.826495\n",
      "[404]\tvalidation_0-auc:-0.826499\n",
      "[405]\tvalidation_0-auc:-0.826498\n",
      "[406]\tvalidation_0-auc:-0.826497\n",
      "[407]\tvalidation_0-auc:-0.826497\n",
      "[408]\tvalidation_0-auc:-0.826504\n",
      "[409]\tvalidation_0-auc:-0.826507\n",
      "[410]\tvalidation_0-auc:-0.826517\n",
      "[411]\tvalidation_0-auc:-0.826539\n",
      "[412]\tvalidation_0-auc:-0.826551\n",
      "[413]\tvalidation_0-auc:-0.826571\n",
      "[414]\tvalidation_0-auc:-0.826591\n",
      "[415]\tvalidation_0-auc:-0.826598\n",
      "[416]\tvalidation_0-auc:-0.826600\n",
      "[417]\tvalidation_0-auc:-0.826613\n",
      "[418]\tvalidation_0-auc:-0.826621\n",
      "[419]\tvalidation_0-auc:-0.826630\n",
      "[420]\tvalidation_0-auc:-0.826631\n",
      "[421]\tvalidation_0-auc:-0.826648\n",
      "[422]\tvalidation_0-auc:-0.826650\n",
      "[423]\tvalidation_0-auc:-0.826651\n",
      "[424]\tvalidation_0-auc:-0.826653\n",
      "[425]\tvalidation_0-auc:-0.826659\n",
      "[426]\tvalidation_0-auc:-0.826664\n",
      "[427]\tvalidation_0-auc:-0.826669\n",
      "[428]\tvalidation_0-auc:-0.826677\n",
      "[429]\tvalidation_0-auc:-0.826676\n",
      "[430]\tvalidation_0-auc:-0.826686\n",
      "[431]\tvalidation_0-auc:-0.826695\n",
      "[432]\tvalidation_0-auc:-0.826700\n",
      "[433]\tvalidation_0-auc:-0.826677\n",
      "[434]\tvalidation_0-auc:-0.826679\n",
      "[435]\tvalidation_0-auc:-0.826684\n",
      "[436]\tvalidation_0-auc:-0.826732\n",
      "[437]\tvalidation_0-auc:-0.826742\n",
      "[438]\tvalidation_0-auc:-0.826749\n",
      "[439]\tvalidation_0-auc:-0.826768\n",
      "[440]\tvalidation_0-auc:-0.826774\n",
      "[441]\tvalidation_0-auc:-0.826777\n",
      "[442]\tvalidation_0-auc:-0.826778\n",
      "[443]\tvalidation_0-auc:-0.826781\n",
      "[444]\tvalidation_0-auc:-0.826779\n",
      "[445]\tvalidation_0-auc:-0.826782\n",
      "[446]\tvalidation_0-auc:-0.826801\n",
      "[447]\tvalidation_0-auc:-0.826804\n",
      "[448]\tvalidation_0-auc:-0.826806\n",
      "[449]\tvalidation_0-auc:-0.826812\n",
      "[450]\tvalidation_0-auc:-0.826829\n",
      "[451]\tvalidation_0-auc:-0.826840\n",
      "[452]\tvalidation_0-auc:-0.826853\n",
      "[453]\tvalidation_0-auc:-0.826864\n",
      "[454]\tvalidation_0-auc:-0.826866\n",
      "[455]\tvalidation_0-auc:-0.826874\n",
      "[456]\tvalidation_0-auc:-0.826879\n",
      "[457]\tvalidation_0-auc:-0.826871\n",
      "[458]\tvalidation_0-auc:-0.826905\n",
      "[459]\tvalidation_0-auc:-0.826923\n",
      "[460]\tvalidation_0-auc:-0.826950\n",
      "[461]\tvalidation_0-auc:-0.826960\n",
      "[462]\tvalidation_0-auc:-0.826981\n",
      "[463]\tvalidation_0-auc:-0.827002\n",
      "[464]\tvalidation_0-auc:-0.827007\n",
      "[465]\tvalidation_0-auc:-0.827016\n",
      "[466]\tvalidation_0-auc:-0.827026\n",
      "[467]\tvalidation_0-auc:-0.827026\n",
      "[468]\tvalidation_0-auc:-0.827027\n",
      "[469]\tvalidation_0-auc:-0.827028\n",
      "[470]\tvalidation_0-auc:-0.827025\n",
      "[471]\tvalidation_0-auc:-0.827040\n",
      "[472]\tvalidation_0-auc:-0.827037\n",
      "[473]\tvalidation_0-auc:-0.827038\n",
      "[474]\tvalidation_0-auc:-0.827039\n",
      "[475]\tvalidation_0-auc:-0.827041\n",
      "[476]\tvalidation_0-auc:-0.827043\n",
      "[477]\tvalidation_0-auc:-0.827048\n",
      "[478]\tvalidation_0-auc:-0.827069\n",
      "[479]\tvalidation_0-auc:-0.827075\n",
      "[480]\tvalidation_0-auc:-0.827103\n",
      "[481]\tvalidation_0-auc:-0.827115\n",
      "[482]\tvalidation_0-auc:-0.827119\n",
      "[483]\tvalidation_0-auc:-0.827128\n",
      "[484]\tvalidation_0-auc:-0.827131\n",
      "[485]\tvalidation_0-auc:-0.827135\n",
      "[486]\tvalidation_0-auc:-0.827135\n",
      "[487]\tvalidation_0-auc:-0.827154\n",
      "[488]\tvalidation_0-auc:-0.827167\n",
      "[489]\tvalidation_0-auc:-0.827166\n",
      "[490]\tvalidation_0-auc:-0.827177\n",
      "[491]\tvalidation_0-auc:-0.827178\n",
      "[492]\tvalidation_0-auc:-0.827215\n",
      "[493]\tvalidation_0-auc:-0.827225\n",
      "[494]\tvalidation_0-auc:-0.827247\n",
      "[495]\tvalidation_0-auc:-0.827259\n",
      "[496]\tvalidation_0-auc:-0.827260\n",
      "[497]\tvalidation_0-auc:-0.827260\n",
      "[498]\tvalidation_0-auc:-0.827252\n",
      "[499]\tvalidation_0-auc:-0.827271\n",
      "[500]\tvalidation_0-auc:-0.827297\n",
      "[501]\tvalidation_0-auc:-0.827303\n",
      "[502]\tvalidation_0-auc:-0.827321\n",
      "[503]\tvalidation_0-auc:-0.827325\n",
      "[504]\tvalidation_0-auc:-0.827333\n",
      "[505]\tvalidation_0-auc:-0.827337\n",
      "[506]\tvalidation_0-auc:-0.827349\n",
      "[507]\tvalidation_0-auc:-0.827357\n",
      "[508]\tvalidation_0-auc:-0.827383\n",
      "[509]\tvalidation_0-auc:-0.827391\n",
      "[510]\tvalidation_0-auc:-0.827391\n",
      "[511]\tvalidation_0-auc:-0.827392\n",
      "[512]\tvalidation_0-auc:-0.827393\n",
      "[513]\tvalidation_0-auc:-0.827399\n",
      "[514]\tvalidation_0-auc:-0.827426\n",
      "[515]\tvalidation_0-auc:-0.827453\n",
      "[516]\tvalidation_0-auc:-0.827463\n",
      "[517]\tvalidation_0-auc:-0.827477\n",
      "[518]\tvalidation_0-auc:-0.827484\n",
      "[519]\tvalidation_0-auc:-0.827504\n",
      "[520]\tvalidation_0-auc:-0.827504\n",
      "[521]\tvalidation_0-auc:-0.827507\n",
      "[522]\tvalidation_0-auc:-0.827511\n",
      "[523]\tvalidation_0-auc:-0.827539\n",
      "[524]\tvalidation_0-auc:-0.827546\n",
      "[525]\tvalidation_0-auc:-0.827544\n",
      "[526]\tvalidation_0-auc:-0.827546\n",
      "[527]\tvalidation_0-auc:-0.827550\n",
      "[528]\tvalidation_0-auc:-0.827557\n",
      "[529]\tvalidation_0-auc:-0.827577\n",
      "[530]\tvalidation_0-auc:-0.827577\n",
      "[531]\tvalidation_0-auc:-0.827576\n",
      "[532]\tvalidation_0-auc:-0.827581\n",
      "[533]\tvalidation_0-auc:-0.827580\n",
      "[534]\tvalidation_0-auc:-0.827582\n",
      "[535]\tvalidation_0-auc:-0.827587\n",
      "[536]\tvalidation_0-auc:-0.827601\n",
      "[537]\tvalidation_0-auc:-0.827605\n",
      "[538]\tvalidation_0-auc:-0.827605\n",
      "[539]\tvalidation_0-auc:-0.827608\n",
      "[540]\tvalidation_0-auc:-0.827609\n",
      "[541]\tvalidation_0-auc:-0.827618\n",
      "[542]\tvalidation_0-auc:-0.827619\n",
      "[543]\tvalidation_0-auc:-0.827619\n",
      "[544]\tvalidation_0-auc:-0.827636\n",
      "[545]\tvalidation_0-auc:-0.827645\n",
      "[546]\tvalidation_0-auc:-0.827654\n",
      "[547]\tvalidation_0-auc:-0.827652\n",
      "[548]\tvalidation_0-auc:-0.827660\n",
      "[549]\tvalidation_0-auc:-0.827658\n",
      "[550]\tvalidation_0-auc:-0.827656\n",
      "[551]\tvalidation_0-auc:-0.827670\n",
      "[552]\tvalidation_0-auc:-0.827676\n",
      "[553]\tvalidation_0-auc:-0.827680\n",
      "[554]\tvalidation_0-auc:-0.827694\n",
      "[555]\tvalidation_0-auc:-0.827697\n",
      "[556]\tvalidation_0-auc:-0.827694\n",
      "[557]\tvalidation_0-auc:-0.827703\n",
      "[558]\tvalidation_0-auc:-0.827698\n",
      "[559]\tvalidation_0-auc:-0.827698\n",
      "[560]\tvalidation_0-auc:-0.827702\n",
      "[561]\tvalidation_0-auc:-0.827706\n",
      "[562]\tvalidation_0-auc:-0.827710\n",
      "[563]\tvalidation_0-auc:-0.827710\n",
      "[564]\tvalidation_0-auc:-0.827730\n",
      "[565]\tvalidation_0-auc:-0.827741\n",
      "[566]\tvalidation_0-auc:-0.827782\n",
      "[567]\tvalidation_0-auc:-0.827795\n",
      "[568]\tvalidation_0-auc:-0.827797\n",
      "[569]\tvalidation_0-auc:-0.827797\n",
      "[570]\tvalidation_0-auc:-0.827803\n",
      "[571]\tvalidation_0-auc:-0.827806\n",
      "[572]\tvalidation_0-auc:-0.827823\n",
      "[573]\tvalidation_0-auc:-0.827829\n",
      "[574]\tvalidation_0-auc:-0.827826\n",
      "[575]\tvalidation_0-auc:-0.827855\n",
      "[576]\tvalidation_0-auc:-0.827867\n",
      "[577]\tvalidation_0-auc:-0.827889\n",
      "[578]\tvalidation_0-auc:-0.827893\n",
      "[579]\tvalidation_0-auc:-0.827901\n",
      "[580]\tvalidation_0-auc:-0.827897\n",
      "[581]\tvalidation_0-auc:-0.827897\n",
      "[582]\tvalidation_0-auc:-0.827903\n",
      "[583]\tvalidation_0-auc:-0.827911\n",
      "[584]\tvalidation_0-auc:-0.827909\n",
      "[585]\tvalidation_0-auc:-0.827943\n",
      "[586]\tvalidation_0-auc:-0.827946\n",
      "[587]\tvalidation_0-auc:-0.827953\n",
      "[588]\tvalidation_0-auc:-0.827958\n",
      "[589]\tvalidation_0-auc:-0.827957\n",
      "[590]\tvalidation_0-auc:-0.827954\n",
      "[591]\tvalidation_0-auc:-0.827950\n",
      "[592]\tvalidation_0-auc:-0.827949\n",
      "[593]\tvalidation_0-auc:-0.827950\n",
      "[594]\tvalidation_0-auc:-0.827959\n",
      "[595]\tvalidation_0-auc:-0.827958\n",
      "[596]\tvalidation_0-auc:-0.827959\n",
      "[597]\tvalidation_0-auc:-0.827975\n",
      "[598]\tvalidation_0-auc:-0.827979\n",
      "[599]\tvalidation_0-auc:-0.827984\n",
      "[600]\tvalidation_0-auc:-0.827978\n",
      "[601]\tvalidation_0-auc:-0.827992\n",
      "[602]\tvalidation_0-auc:-0.828003\n",
      "[603]\tvalidation_0-auc:-0.828005\n",
      "[604]\tvalidation_0-auc:-0.828023\n",
      "[605]\tvalidation_0-auc:-0.828017\n",
      "[606]\tvalidation_0-auc:-0.828042\n",
      "[607]\tvalidation_0-auc:-0.828056\n",
      "[608]\tvalidation_0-auc:-0.828052\n",
      "[609]\tvalidation_0-auc:-0.828054\n",
      "[610]\tvalidation_0-auc:-0.828052\n",
      "[611]\tvalidation_0-auc:-0.828037\n",
      "[612]\tvalidation_0-auc:-0.828033\n",
      "[613]\tvalidation_0-auc:-0.828034\n",
      "[614]\tvalidation_0-auc:-0.828037\n",
      "[615]\tvalidation_0-auc:-0.828036\n",
      "[616]\tvalidation_0-auc:-0.828045\n",
      "[617]\tvalidation_0-auc:-0.828052\n",
      "[618]\tvalidation_0-auc:-0.828073\n",
      "[619]\tvalidation_0-auc:-0.828075\n",
      "[620]\tvalidation_0-auc:-0.828091\n",
      "[621]\tvalidation_0-auc:-0.828103\n",
      "[622]\tvalidation_0-auc:-0.828116\n",
      "[623]\tvalidation_0-auc:-0.828118\n",
      "[624]\tvalidation_0-auc:-0.828120\n",
      "[625]\tvalidation_0-auc:-0.828123\n",
      "[626]\tvalidation_0-auc:-0.828128\n",
      "[627]\tvalidation_0-auc:-0.828131\n",
      "[628]\tvalidation_0-auc:-0.828131\n",
      "[629]\tvalidation_0-auc:-0.828122\n",
      "[630]\tvalidation_0-auc:-0.828125\n",
      "[631]\tvalidation_0-auc:-0.828142\n",
      "[632]\tvalidation_0-auc:-0.828148\n",
      "[633]\tvalidation_0-auc:-0.828149\n",
      "[634]\tvalidation_0-auc:-0.828178\n",
      "[635]\tvalidation_0-auc:-0.828181\n",
      "[636]\tvalidation_0-auc:-0.828193\n",
      "[637]\tvalidation_0-auc:-0.828197\n",
      "[638]\tvalidation_0-auc:-0.828200\n",
      "[639]\tvalidation_0-auc:-0.828191\n",
      "[640]\tvalidation_0-auc:-0.828193\n",
      "[641]\tvalidation_0-auc:-0.828206\n",
      "[642]\tvalidation_0-auc:-0.828213\n",
      "[643]\tvalidation_0-auc:-0.828215\n",
      "[644]\tvalidation_0-auc:-0.828232\n",
      "[645]\tvalidation_0-auc:-0.828227\n",
      "[646]\tvalidation_0-auc:-0.828242\n",
      "[647]\tvalidation_0-auc:-0.828232\n",
      "[648]\tvalidation_0-auc:-0.828290\n",
      "[649]\tvalidation_0-auc:-0.828293\n",
      "[650]\tvalidation_0-auc:-0.828307\n",
      "[651]\tvalidation_0-auc:-0.828303\n",
      "[652]\tvalidation_0-auc:-0.828318\n",
      "[653]\tvalidation_0-auc:-0.828317\n",
      "[654]\tvalidation_0-auc:-0.828332\n",
      "[655]\tvalidation_0-auc:-0.828342\n",
      "[656]\tvalidation_0-auc:-0.828344\n",
      "[657]\tvalidation_0-auc:-0.828367\n",
      "[658]\tvalidation_0-auc:-0.828363\n",
      "[659]\tvalidation_0-auc:-0.828364\n",
      "[660]\tvalidation_0-auc:-0.828366\n",
      "[661]\tvalidation_0-auc:-0.828368\n",
      "[662]\tvalidation_0-auc:-0.828373\n",
      "[663]\tvalidation_0-auc:-0.828375\n",
      "[664]\tvalidation_0-auc:-0.828378\n",
      "[665]\tvalidation_0-auc:-0.828377\n",
      "[666]\tvalidation_0-auc:-0.828416\n",
      "[667]\tvalidation_0-auc:-0.828464\n",
      "[668]\tvalidation_0-auc:-0.828470\n",
      "[669]\tvalidation_0-auc:-0.828486\n",
      "[670]\tvalidation_0-auc:-0.828493\n",
      "[671]\tvalidation_0-auc:-0.828475\n",
      "[672]\tvalidation_0-auc:-0.828494\n",
      "[673]\tvalidation_0-auc:-0.828496\n",
      "[674]\tvalidation_0-auc:-0.828495\n",
      "[675]\tvalidation_0-auc:-0.828497\n",
      "[676]\tvalidation_0-auc:-0.828493\n",
      "[677]\tvalidation_0-auc:-0.828494\n",
      "[678]\tvalidation_0-auc:-0.828496\n",
      "[679]\tvalidation_0-auc:-0.828499\n",
      "[680]\tvalidation_0-auc:-0.828513\n",
      "[681]\tvalidation_0-auc:-0.828522\n",
      "[682]\tvalidation_0-auc:-0.828541\n",
      "[683]\tvalidation_0-auc:-0.828541\n",
      "[684]\tvalidation_0-auc:-0.828542\n",
      "[685]\tvalidation_0-auc:-0.828544\n",
      "[686]\tvalidation_0-auc:-0.828543\n",
      "[687]\tvalidation_0-auc:-0.828541\n",
      "[688]\tvalidation_0-auc:-0.828555\n",
      "[689]\tvalidation_0-auc:-0.828553\n",
      "[690]\tvalidation_0-auc:-0.828550\n",
      "[691]\tvalidation_0-auc:-0.828546\n",
      "[692]\tvalidation_0-auc:-0.828548\n",
      "[693]\tvalidation_0-auc:-0.828499\n",
      "[694]\tvalidation_0-auc:-0.828492\n",
      "[695]\tvalidation_0-auc:-0.828485\n",
      "[696]\tvalidation_0-auc:-0.828485\n",
      "[697]\tvalidation_0-auc:-0.828502\n",
      "[698]\tvalidation_0-auc:-0.828502\n",
      "[699]\tvalidation_0-auc:-0.828516\n",
      "[700]\tvalidation_0-auc:-0.828525\n",
      "[701]\tvalidation_0-auc:-0.828536\n",
      "[702]\tvalidation_0-auc:-0.828542\n",
      "[703]\tvalidation_0-auc:-0.828535\n",
      "[704]\tvalidation_0-auc:-0.828533\n",
      "[705]\tvalidation_0-auc:-0.828540\n",
      "[706]\tvalidation_0-auc:-0.828555\n",
      "[707]\tvalidation_0-auc:-0.828554\n",
      "[708]\tvalidation_0-auc:-0.828560\n",
      "[709]\tvalidation_0-auc:-0.828560\n",
      "[710]\tvalidation_0-auc:-0.828565\n",
      "[711]\tvalidation_0-auc:-0.828565\n",
      "[712]\tvalidation_0-auc:-0.828571\n",
      "[713]\tvalidation_0-auc:-0.828576\n",
      "[714]\tvalidation_0-auc:-0.828587\n",
      "[715]\tvalidation_0-auc:-0.828585\n",
      "[716]\tvalidation_0-auc:-0.828596\n",
      "[717]\tvalidation_0-auc:-0.828595\n",
      "[718]\tvalidation_0-auc:-0.828597\n",
      "[719]\tvalidation_0-auc:-0.828600\n",
      "[720]\tvalidation_0-auc:-0.828627\n",
      "[721]\tvalidation_0-auc:-0.828627\n",
      "[722]\tvalidation_0-auc:-0.828631\n",
      "[723]\tvalidation_0-auc:-0.828636\n",
      "[724]\tvalidation_0-auc:-0.828652\n",
      "[725]\tvalidation_0-auc:-0.828667\n",
      "[726]\tvalidation_0-auc:-0.828678\n",
      "[727]\tvalidation_0-auc:-0.828676\n",
      "[728]\tvalidation_0-auc:-0.828689\n",
      "[729]\tvalidation_0-auc:-0.828693\n",
      "[730]\tvalidation_0-auc:-0.828690\n",
      "[731]\tvalidation_0-auc:-0.828695\n",
      "[732]\tvalidation_0-auc:-0.828689\n",
      "[733]\tvalidation_0-auc:-0.828687\n",
      "[734]\tvalidation_0-auc:-0.828690\n",
      "[735]\tvalidation_0-auc:-0.828695\n",
      "[736]\tvalidation_0-auc:-0.828701\n",
      "[737]\tvalidation_0-auc:-0.828705\n",
      "[738]\tvalidation_0-auc:-0.828719\n",
      "[739]\tvalidation_0-auc:-0.828715\n",
      "[740]\tvalidation_0-auc:-0.828716\n",
      "[741]\tvalidation_0-auc:-0.828728\n",
      "[742]\tvalidation_0-auc:-0.828728\n",
      "[743]\tvalidation_0-auc:-0.828737\n",
      "[744]\tvalidation_0-auc:-0.828736\n",
      "[745]\tvalidation_0-auc:-0.828738\n",
      "[746]\tvalidation_0-auc:-0.828734\n",
      "[747]\tvalidation_0-auc:-0.828731\n",
      "[748]\tvalidation_0-auc:-0.828735\n",
      "[749]\tvalidation_0-auc:-0.828739\n",
      "[750]\tvalidation_0-auc:-0.828736\n",
      "[751]\tvalidation_0-auc:-0.828736\n",
      "[752]\tvalidation_0-auc:-0.828784\n",
      "[753]\tvalidation_0-auc:-0.828784\n",
      "[754]\tvalidation_0-auc:-0.828784\n",
      "[755]\tvalidation_0-auc:-0.828784\n",
      "[756]\tvalidation_0-auc:-0.828790\n",
      "[757]\tvalidation_0-auc:-0.828796\n",
      "[758]\tvalidation_0-auc:-0.828794\n",
      "[759]\tvalidation_0-auc:-0.828788\n",
      "[760]\tvalidation_0-auc:-0.828788\n",
      "[761]\tvalidation_0-auc:-0.828788\n",
      "[762]\tvalidation_0-auc:-0.828791\n",
      "[763]\tvalidation_0-auc:-0.828801\n",
      "[764]\tvalidation_0-auc:-0.828799\n",
      "[765]\tvalidation_0-auc:-0.828804\n",
      "[766]\tvalidation_0-auc:-0.828807\n",
      "[767]\tvalidation_0-auc:-0.828830\n",
      "[768]\tvalidation_0-auc:-0.828831\n",
      "[769]\tvalidation_0-auc:-0.828838\n",
      "[770]\tvalidation_0-auc:-0.828841\n",
      "[771]\tvalidation_0-auc:-0.828853\n",
      "[772]\tvalidation_0-auc:-0.828855\n",
      "[773]\tvalidation_0-auc:-0.828871\n",
      "[774]\tvalidation_0-auc:-0.828869\n",
      "[775]\tvalidation_0-auc:-0.828866\n",
      "[776]\tvalidation_0-auc:-0.828860\n",
      "[777]\tvalidation_0-auc:-0.828860\n",
      "[778]\tvalidation_0-auc:-0.828855\n",
      "[779]\tvalidation_0-auc:-0.828856\n",
      "[780]\tvalidation_0-auc:-0.828863\n",
      "[781]\tvalidation_0-auc:-0.828875\n",
      "[782]\tvalidation_0-auc:-0.828879\n",
      "[783]\tvalidation_0-auc:-0.828883\n",
      "[784]\tvalidation_0-auc:-0.828890\n",
      "[785]\tvalidation_0-auc:-0.828889\n",
      "[786]\tvalidation_0-auc:-0.828903\n",
      "[787]\tvalidation_0-auc:-0.828914\n",
      "[788]\tvalidation_0-auc:-0.828915\n",
      "[789]\tvalidation_0-auc:-0.828918\n",
      "[790]\tvalidation_0-auc:-0.828937\n",
      "[791]\tvalidation_0-auc:-0.828948\n",
      "[792]\tvalidation_0-auc:-0.828947\n",
      "[793]\tvalidation_0-auc:-0.828953\n",
      "[794]\tvalidation_0-auc:-0.828959\n",
      "[795]\tvalidation_0-auc:-0.828959\n",
      "[796]\tvalidation_0-auc:-0.828958\n",
      "[797]\tvalidation_0-auc:-0.828957\n",
      "[798]\tvalidation_0-auc:-0.828972\n",
      "[799]\tvalidation_0-auc:-0.828967\n",
      "[800]\tvalidation_0-auc:-0.828988\n",
      "[801]\tvalidation_0-auc:-0.828988\n",
      "[802]\tvalidation_0-auc:-0.828990\n",
      "[803]\tvalidation_0-auc:-0.828997\n",
      "[804]\tvalidation_0-auc:-0.828995\n",
      "[805]\tvalidation_0-auc:-0.829010\n",
      "[806]\tvalidation_0-auc:-0.829011\n",
      "[807]\tvalidation_0-auc:-0.829018\n",
      "[808]\tvalidation_0-auc:-0.829021\n",
      "[809]\tvalidation_0-auc:-0.829021\n",
      "[810]\tvalidation_0-auc:-0.829021\n",
      "[811]\tvalidation_0-auc:-0.829022\n",
      "[812]\tvalidation_0-auc:-0.829022\n",
      "[813]\tvalidation_0-auc:-0.829022\n",
      "[814]\tvalidation_0-auc:-0.829019\n",
      "[815]\tvalidation_0-auc:-0.829028\n",
      "[816]\tvalidation_0-auc:-0.829034\n",
      "[817]\tvalidation_0-auc:-0.829036\n",
      "[818]\tvalidation_0-auc:-0.829041\n",
      "[819]\tvalidation_0-auc:-0.829046\n",
      "[820]\tvalidation_0-auc:-0.829055\n",
      "[821]\tvalidation_0-auc:-0.829054\n",
      "[822]\tvalidation_0-auc:-0.829055\n",
      "[823]\tvalidation_0-auc:-0.829052\n",
      "[824]\tvalidation_0-auc:-0.829053\n",
      "[825]\tvalidation_0-auc:-0.829061\n",
      "[826]\tvalidation_0-auc:-0.829064\n",
      "[827]\tvalidation_0-auc:-0.829057\n",
      "[828]\tvalidation_0-auc:-0.829058\n",
      "[829]\tvalidation_0-auc:-0.829065\n",
      "[830]\tvalidation_0-auc:-0.829080\n",
      "[831]\tvalidation_0-auc:-0.829078\n",
      "[832]\tvalidation_0-auc:-0.829073\n",
      "[833]\tvalidation_0-auc:-0.829081\n",
      "[834]\tvalidation_0-auc:-0.829080\n",
      "[835]\tvalidation_0-auc:-0.829093\n",
      "[836]\tvalidation_0-auc:-0.829098\n",
      "[837]\tvalidation_0-auc:-0.829105\n",
      "[838]\tvalidation_0-auc:-0.829109\n",
      "[839]\tvalidation_0-auc:-0.829108\n",
      "[840]\tvalidation_0-auc:-0.829110\n",
      "[841]\tvalidation_0-auc:-0.829109\n",
      "[842]\tvalidation_0-auc:-0.829110\n",
      "[843]\tvalidation_0-auc:-0.829110\n",
      "[844]\tvalidation_0-auc:-0.829115\n",
      "[845]\tvalidation_0-auc:-0.829118\n",
      "[846]\tvalidation_0-auc:-0.829126\n",
      "[847]\tvalidation_0-auc:-0.829125\n",
      "[848]\tvalidation_0-auc:-0.829130\n",
      "[849]\tvalidation_0-auc:-0.829128\n",
      "[850]\tvalidation_0-auc:-0.829124\n",
      "[851]\tvalidation_0-auc:-0.829135\n",
      "[852]\tvalidation_0-auc:-0.829135\n",
      "[853]\tvalidation_0-auc:-0.829145\n",
      "[854]\tvalidation_0-auc:-0.829150\n",
      "[855]\tvalidation_0-auc:-0.829155\n",
      "[856]\tvalidation_0-auc:-0.829161\n",
      "[857]\tvalidation_0-auc:-0.829163\n",
      "[858]\tvalidation_0-auc:-0.829162\n",
      "[859]\tvalidation_0-auc:-0.829173\n",
      "[860]\tvalidation_0-auc:-0.829175\n",
      "[861]\tvalidation_0-auc:-0.829174\n",
      "[862]\tvalidation_0-auc:-0.829172\n",
      "[863]\tvalidation_0-auc:-0.829176\n",
      "[864]\tvalidation_0-auc:-0.829178\n",
      "[865]\tvalidation_0-auc:-0.829187\n",
      "[866]\tvalidation_0-auc:-0.829184\n",
      "[867]\tvalidation_0-auc:-0.829183\n",
      "[868]\tvalidation_0-auc:-0.829183\n",
      "[869]\tvalidation_0-auc:-0.829185\n",
      "[870]\tvalidation_0-auc:-0.829184\n",
      "[871]\tvalidation_0-auc:-0.829184\n",
      "[872]\tvalidation_0-auc:-0.829191\n",
      "[873]\tvalidation_0-auc:-0.829192\n",
      "[874]\tvalidation_0-auc:-0.829197\n",
      "[875]\tvalidation_0-auc:-0.829195\n",
      "[876]\tvalidation_0-auc:-0.829207\n",
      "[877]\tvalidation_0-auc:-0.829211\n",
      "[878]\tvalidation_0-auc:-0.829207\n",
      "[879]\tvalidation_0-auc:-0.829206\n",
      "[880]\tvalidation_0-auc:-0.829196\n",
      "[881]\tvalidation_0-auc:-0.829200\n",
      "[882]\tvalidation_0-auc:-0.829207\n",
      "[883]\tvalidation_0-auc:-0.829207\n",
      "[884]\tvalidation_0-auc:-0.829205\n",
      "[885]\tvalidation_0-auc:-0.829206\n",
      "[886]\tvalidation_0-auc:-0.829202\n",
      "[887]\tvalidation_0-auc:-0.829212\n",
      "[888]\tvalidation_0-auc:-0.829216\n",
      "[889]\tvalidation_0-auc:-0.829219\n",
      "[890]\tvalidation_0-auc:-0.829219\n",
      "[891]\tvalidation_0-auc:-0.829222\n",
      "[892]\tvalidation_0-auc:-0.829216\n",
      "[893]\tvalidation_0-auc:-0.829208\n",
      "[894]\tvalidation_0-auc:-0.829223\n",
      "[895]\tvalidation_0-auc:-0.829229\n",
      "[896]\tvalidation_0-auc:-0.829229\n",
      "[897]\tvalidation_0-auc:-0.829240\n",
      "[898]\tvalidation_0-auc:-0.829246\n",
      "[899]\tvalidation_0-auc:-0.829245\n",
      "[900]\tvalidation_0-auc:-0.829236\n",
      "[901]\tvalidation_0-auc:-0.829239\n",
      "[902]\tvalidation_0-auc:-0.829246\n",
      "[903]\tvalidation_0-auc:-0.829243\n",
      "[904]\tvalidation_0-auc:-0.829256\n",
      "[905]\tvalidation_0-auc:-0.829261\n",
      "[906]\tvalidation_0-auc:-0.829265\n",
      "[907]\tvalidation_0-auc:-0.829273\n",
      "[908]\tvalidation_0-auc:-0.829278\n",
      "[909]\tvalidation_0-auc:-0.829276\n",
      "[910]\tvalidation_0-auc:-0.829272\n",
      "[911]\tvalidation_0-auc:-0.829282\n",
      "[912]\tvalidation_0-auc:-0.829283\n",
      "[913]\tvalidation_0-auc:-0.829286\n",
      "[914]\tvalidation_0-auc:-0.829254\n",
      "[915]\tvalidation_0-auc:-0.829252\n",
      "[916]\tvalidation_0-auc:-0.829250\n",
      "[917]\tvalidation_0-auc:-0.829246\n",
      "[918]\tvalidation_0-auc:-0.829244\n",
      "[919]\tvalidation_0-auc:-0.829244\n",
      "[920]\tvalidation_0-auc:-0.829252\n",
      "[921]\tvalidation_0-auc:-0.829258\n",
      "[922]\tvalidation_0-auc:-0.829260\n",
      "[923]\tvalidation_0-auc:-0.829264\n",
      "[924]\tvalidation_0-auc:-0.829254\n",
      "[925]\tvalidation_0-auc:-0.829257\n",
      "[926]\tvalidation_0-auc:-0.829254\n",
      "[927]\tvalidation_0-auc:-0.829250\n",
      "[928]\tvalidation_0-auc:-0.829249\n",
      "[929]\tvalidation_0-auc:-0.829247\n",
      "[930]\tvalidation_0-auc:-0.829248\n",
      "[931]\tvalidation_0-auc:-0.829256\n",
      "[932]\tvalidation_0-auc:-0.829256\n",
      "[933]\tvalidation_0-auc:-0.829255\n",
      "[934]\tvalidation_0-auc:-0.829267\n",
      "[935]\tvalidation_0-auc:-0.829267\n",
      "[936]\tvalidation_0-auc:-0.829276\n",
      "[937]\tvalidation_0-auc:-0.829289\n",
      "[938]\tvalidation_0-auc:-0.829295\n",
      "[939]\tvalidation_0-auc:-0.829307\n",
      "[940]\tvalidation_0-auc:-0.829302\n",
      "[941]\tvalidation_0-auc:-0.829304\n",
      "[942]\tvalidation_0-auc:-0.829323\n",
      "[943]\tvalidation_0-auc:-0.829328\n",
      "[944]\tvalidation_0-auc:-0.829337\n",
      "[945]\tvalidation_0-auc:-0.829337\n",
      "[946]\tvalidation_0-auc:-0.829342\n",
      "[947]\tvalidation_0-auc:-0.829343\n",
      "[948]\tvalidation_0-auc:-0.829334\n",
      "[949]\tvalidation_0-auc:-0.829335\n",
      "[950]\tvalidation_0-auc:-0.829336\n",
      "[951]\tvalidation_0-auc:-0.829321\n",
      "[952]\tvalidation_0-auc:-0.829321\n",
      "[953]\tvalidation_0-auc:-0.829330\n",
      "[954]\tvalidation_0-auc:-0.829330\n",
      "[955]\tvalidation_0-auc:-0.829330\n",
      "[956]\tvalidation_0-auc:-0.829315\n",
      "[957]\tvalidation_0-auc:-0.829310\n",
      "[958]\tvalidation_0-auc:-0.829309\n",
      "[959]\tvalidation_0-auc:-0.829313\n",
      "[960]\tvalidation_0-auc:-0.829314\n",
      "[961]\tvalidation_0-auc:-0.829299\n",
      "[962]\tvalidation_0-auc:-0.829301\n",
      "[963]\tvalidation_0-auc:-0.829302\n",
      "[964]\tvalidation_0-auc:-0.829314\n",
      "[965]\tvalidation_0-auc:-0.829315\n",
      "[966]\tvalidation_0-auc:-0.829315\n",
      "[967]\tvalidation_0-auc:-0.829322\n",
      "[968]\tvalidation_0-auc:-0.829322\n",
      "[969]\tvalidation_0-auc:-0.829327\n",
      "[970]\tvalidation_0-auc:-0.829325\n",
      "[971]\tvalidation_0-auc:-0.829323\n",
      "[972]\tvalidation_0-auc:-0.829324\n",
      "[973]\tvalidation_0-auc:-0.829315\n",
      "[974]\tvalidation_0-auc:-0.829314\n",
      "[975]\tvalidation_0-auc:-0.829320\n",
      "[976]\tvalidation_0-auc:-0.829330\n",
      "[977]\tvalidation_0-auc:-0.829332\n",
      "[978]\tvalidation_0-auc:-0.829330\n",
      "[979]\tvalidation_0-auc:-0.829291\n",
      "[980]\tvalidation_0-auc:-0.829297\n",
      "[981]\tvalidation_0-auc:-0.829300\n",
      "[982]\tvalidation_0-auc:-0.829299\n",
      "[983]\tvalidation_0-auc:-0.829299\n",
      "[984]\tvalidation_0-auc:-0.829301\n",
      "[985]\tvalidation_0-auc:-0.829298\n",
      "[986]\tvalidation_0-auc:-0.829295\n",
      "[987]\tvalidation_0-auc:-0.829300\n",
      "[988]\tvalidation_0-auc:-0.829302\n",
      "[989]\tvalidation_0-auc:-0.829306\n",
      "[990]\tvalidation_0-auc:-0.829305\n",
      "[991]\tvalidation_0-auc:-0.829306\n",
      "[992]\tvalidation_0-auc:-0.829305\n",
      "[993]\tvalidation_0-auc:-0.829309\n",
      "[994]\tvalidation_0-auc:-0.829317\n",
      "[995]\tvalidation_0-auc:-0.829316\n",
      "[996]\tvalidation_0-auc:-0.829315\n",
      "[997]\tvalidation_0-auc:-0.829314\n",
      "[998]\tvalidation_0-auc:-0.829312\n",
      "[999]\tvalidation_0-auc:-0.829306\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'best_ntree_limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1f2678fe6831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0myval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mtrain_pred_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[0mval_pred_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[0mtest_pred_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1f2678fe6831>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[1;34m(xtrain, ytrain, xval, yval, X_test, clf)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtrain_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mval_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtest_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-97df1aa79329>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'best_ntree_limit'"
     ]
    }
   ],
   "source": [
    "def train_and_predict(xtrain, ytrain, xval, yval, X_test, clf):\n",
    "    assert hasattr(clf, 'fit_cv')\n",
    "    assert hasattr(clf, 'predict_proba') or hasattr(clf, 'predict')\n",
    "\n",
    "    clf.fit_cv(xtrain, ytrain, eval_set=(xval, yval))\n",
    "\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "\n",
    "        train_pred_prob = clf.predict_proba(xtrain)\n",
    "        val_pred_prob = clf.predict_proba(xval)\n",
    "        test_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    elif hasattr(clf, 'predict'):\n",
    "        train_pred_prob = clf.predict(xtrain)\n",
    "        val_pred_prob = clf.predict(xval)\n",
    "        test_pred_prob = clf.predict(X_test)\n",
    "\n",
    "    # reshaping and clipping\n",
    "    train_pred_prob = utils.reshapePrediction(train_pred_prob)\n",
    "    val_pred_prob = utils.reshapePrediction(val_pred_prob)\n",
    "    test_pred_prob = utils.reshapePrediction(test_pred_prob)\n",
    "\n",
    "    # getting intergers\n",
    "    train_pred = np.round(train_pred_prob)\n",
    "    val_pred = np.round(val_pred_prob)\n",
    "    test_pred = np.round(test_pred_prob)\n",
    "\n",
    "    return train_pred_prob, train_pred, \\\n",
    "           val_pred_prob, val_pred, \\\n",
    "           test_pred_prob, test_pred\n",
    "\n",
    "# D1 = (X, Y, X_test, test_idx, data_name, col_feats)\n",
    "\n",
    "\n",
    "for clf_indice, data_clf in enumerate(clfs):\n",
    "    print('-' * 50)\n",
    "    print(\"Classifier [%i]\" % clf_indice)\n",
    "\n",
    "    X = data_clf[0][0]\n",
    "    Y = data_clf[0][1]\n",
    "    X_test = data_clf[0][2]\n",
    "    test_idx = data_clf[0][3]\n",
    "    data_name = data_clf[0][4]\n",
    "    col_feats = data_clf[0][5]\n",
    "    clf = data_clf[1]\n",
    "    skf = data_clf[2]\n",
    "    print(clf)\n",
    "\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf_name_short = clf_name[:3]\n",
    "\n",
    "    blend_X = np.zeros((len(X), 1))\n",
    "    blend_X_test = np.zeros((len(X_test), 1))\n",
    "    blend_X_test_fold = np.zeros((len(X_test), len(skf)))\n",
    "\n",
    "    dic_logs = {'name': clf_name, 'feat_importance': None,\n",
    "                'blend_X': blend_X, 'blend_Y': Y,\n",
    "                'blend_X_test': blend_X_test, 'test_idx': test_idx,\n",
    "                'params': None, 'prepro': None, 'best_epoch': [], 'best_val_metric': [],\n",
    "                'train_error': [], 'val_error': []}\n",
    "\n",
    "    filename = '{}_{}_{}f_CV{}'.format(clf_name_short, data_name, X.shape[1], n_folds)\n",
    "\n",
    "    for fold_indice, (train_indices, val_indices) in enumerate(skf):\n",
    "        print(\"Fold [%i]\" % fold_indice)\n",
    "        xtrain = X[train_indices, :]\n",
    "        ytrain = Y[train_indices]\n",
    "        xval = X[val_indices, :]\n",
    "        yval = Y[val_indices]\n",
    "        train_pred_prob, train_pred, \\\n",
    "        val_pred_prob, val_pred, \\\n",
    "        test_pred_prob, test_pred = train_and_predict(xtrain, ytrain, xval, yval, X_test, clf)\n",
    "\n",
    "        # metrics\n",
    "        train_error = utils.eval_func(ytrain, train_pred_prob)\n",
    "        val_error = utils.eval_func(yval, val_pred_prob)\n",
    "\n",
    "        # filling blend data sets\n",
    "        blend_X_test_fold[:, fold_indice] = test_pred_prob\n",
    "\n",
    "        print(\"train/val error: [{0:.4f}|{1:.4f}]\".format(train_error, val_error))\n",
    "        print(utils.confusion_matrix(yval, val_pred))\n",
    "\n",
    "        dic_logs['blend_X'][val_indices, 0] = val_pred_prob\n",
    "        dic_logs['train_error'].append(train_error)\n",
    "        dic_logs['val_error'].append(val_error)\n",
    "        dic_logs['params'] = clf.get_params()\n",
    "        dic_logs['best_epoch'].append(clf.get_best_epoch())\n",
    "        dic_logs['best_val_metric'].append(clf.get_best_val_metric())\n",
    "        dic_logs['feat_importance'] = clf.get_FI(col_feats)\n",
    "\n",
    "    test_pred_prob = np.mean(blend_X_test_fold, axis=1)\n",
    "    dic_logs['blend_X_test'][:, 0] = test_pred_prob\n",
    "\n",
    "    filename += \"{}_{}\".format(clf.get_string_params(), utils.printResults(dic_logs))\n",
    "    print(filename)\n",
    "\n",
    "    if STORE:\n",
    "        utils.saveDicLogs(dic_logs, SAVE_FOLDER + filename + '.p')\n",
    "\n",
    "    # submission\n",
    "    output_filename = SAVE_FOLDER + filename + '.csv'\n",
    "    np.savetxt(output_filename, np.vstack((test_idx, test_pred_prob)).T,\n",
    "               delimiter=',', fmt='%i,%.10f', header='id,probability', comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
