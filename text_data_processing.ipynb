{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "######################\n",
    "## Required Modules ##\n",
    "######################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import json\n",
    "import nltk.corpus\n",
    "try:\n",
    "   import cPickle as pkl\n",
    "except:\n",
    "   import pickle as pkl\n",
    "from csv import DictReader\n",
    "from datetime import datetime\n",
    "from nltk import SnowballStemmer\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models\n",
    "# from ngram import getUnigram, getBigram\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 99)\n",
    "\n",
    "FOLDER = \"/home/evgeny/kaggle/input/\"\n",
    "FOLDER_MEDIA = \"/media/shared_ardalan_evgeny/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "## Setup ##\n",
    "###########\n",
    "stopwords= frozenset(word \\\n",
    "                     for word in nltk.corpus.stopwords.words(\"russian\") \\\n",
    "                     if word!=\"не\")\n",
    "stemmer = SnowballStemmer('russian')\n",
    "engChars = [ord(char) for char in u\"cCyoOBaAKpPeE\"]\n",
    "rusChars = [ord(char) for char in u\"сСуоОВаАКрРеЕ\"]\n",
    "eng_rusTranslateTable = dict(zip(engChars, rusChars))\n",
    "rus_engTranslateTable = dict(zip(rusChars, engChars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tryDivide(x, y):\n",
    "    \"\"\" Try to divide two numbers\"\"\"\n",
    "    s = 0.0\n",
    "    if y != 0.0: s = x / y\n",
    "    return s\n",
    "\n",
    "def correctWord (w):\n",
    "    \"\"\" Corrects word by replacing characters with written similarly depending\n",
    "    on which language the word. \n",
    "    Fraudsters use this technique to avoid detection by anti-fraud algorithms.\n",
    "    \"\"\"\n",
    "    if len(re.findall(r\"[а-я]\",w))>len(re.findall(r\"[a-z]\",w)):\n",
    "        return w.translate(eng_rusTranslateTable)\n",
    "    else:\n",
    "        return w.translate(rus_engTranslateTable)\n",
    "    \n",
    "def getWordCharCount(w):\n",
    "    \"\"\" Char count for a word.\"\"\"\n",
    "    rus = len(re.findall(r\"[а-я]\",w))\n",
    "    eng = len(re.findall(r\"[a-z]\",w))\n",
    "    num = len(re.findall(r\"[0-9]\",w))\n",
    "    c = len(w)    \n",
    "    return c, rus, eng, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTextStatsFeat(text, ndoc, stemmRequired = True,\n",
    "                     excludeStopwordsRequired = True):\n",
    "    \n",
    "    \"\"\" Get stats features for raw text.\n",
    "    These features don't seem to help much.\n",
    "    \"\"\"\n",
    "    #length = len(text)\n",
    "    sentenceCount = len(re.findall(\"[.?!]\", text))\n",
    "    exclamationMarkCount = len(re.findall(\"[!]\", text))\n",
    "    questionMarkCount = len(re.findall(\"[?]\", text))\n",
    "    digitsCount = len(re.findall(\"[0-9]+\", text))\n",
    "    text = text.replace(\",\", \" \").replace(\".\", \" \")\n",
    "    cleanText = re.sub(u'[^a-zа-я0-9]', ' ', text.lower())\n",
    "    wordCount = 0.0\n",
    "    charCount = 0.0\n",
    "    rusCharCount = 0.0\n",
    "    engCharCount = 0.0\n",
    "    numCharCount = 0.0\n",
    "    if excludeStopwordsRequired:\n",
    "        for w in cleanText.split():\n",
    "            if len(w)>1 and w not in stopwords:\n",
    "                if not (not stemmRequired or re.search(\"[0-9a-z]\", w)):\n",
    "                    w = stemmer.stem(w)\n",
    "                wordCount += 1\n",
    "                c, rus, eng, num = getWordCharCount(w)\n",
    "                charCount += c\n",
    "                rusCharCount += rus\n",
    "                engCharCount += eng\n",
    "                numCharCount += num\n",
    "    else:\n",
    "        for w in cleanText.split():\n",
    "            if len(w)>1:\n",
    "                if not (not stemmRequired or re.search(\"[0-9a-z]\", w)):\n",
    "                    w = stemmer.stem(w)\n",
    "                wordCount += 1\n",
    "                c, rus, eng, num = getWordCharCount(w)\n",
    "                charCount += c\n",
    "                rusCharCount += rus\n",
    "                engCharCount += eng\n",
    "                numCharCount += num\n",
    "    # per sentence\n",
    "    wordPerSentence = tryDivide(wordCount, sentenceCount)\n",
    "    charPerSentence = tryDivide(charCount, sentenceCount)\n",
    "    rusCharPerSentence = tryDivide(rusCharCount, sentenceCount)\n",
    "    engCharPerSentence = tryDivide(engCharCount, sentenceCount)\n",
    "    numCharPerSentence = tryDivide(numCharCount, sentenceCount)\n",
    "    # per word\n",
    "    charPerWord = tryDivide(charCount, wordCount)\n",
    "    rusCharPerWord = tryDivide(rusCharCount, wordCount)\n",
    "    engCharPerWord = tryDivide(engCharCount, wordCount)\n",
    "    numCharPerWord = tryDivide(numCharCount, wordCount)\n",
    "    # ratio\n",
    "    rusCharRatio = tryDivide(rusCharCount, charCount)\n",
    "    engCharRatio = tryDivide(engCharCount, charCount)\n",
    "    rusCharVsEngChar = tryDivide(rusCharCount, engCharCount)\n",
    "    engCharVsRusChar = tryDivide(engCharCount, rusCharCount)\n",
    "    numCharVsRusChar = tryDivide(numCharCount, rusCharCount)\n",
    "    numCharVsEngChar = tryDivide(numCharCount, engCharCount)\n",
    "    \n",
    "#     stats = [\n",
    "#         sentenceCount,\n",
    "#         wordCount,\n",
    "#         charCount,\n",
    "#         rusCharCount,\n",
    "#         engCharCount,\n",
    "#         digitsCount,      \n",
    "#         exclamationMarkCount,\n",
    "#         questionMarkCount,\n",
    "# #   per sentence\n",
    "#         wordPerSentence,\n",
    "#         charPerSentence,\n",
    "#         rusCharPerSentence,\n",
    "#         engCharPerSentence,\n",
    "#         numCharPerSentence,\n",
    "# #   per word\n",
    "#         charPerWord,\n",
    "#         rusCharPerWord,\n",
    "#         engCharPerWord,\n",
    "#         numCharPerWord,\n",
    "# #   ratio\n",
    "#         rusCharRatio,\n",
    "#         engCharRatio,\n",
    "#         rusCharVsEngChar,\n",
    "#         engCharVsRusChar,\n",
    "#         numCharVsRusChar,\n",
    "#         numCharVsEngChar,\n",
    "#     ]\n",
    "\n",
    "    stats = {\n",
    "        \"sentenceCount\" + ndoc : sentenceCount,\n",
    "        \"wordCount\" + ndoc : wordCount,\n",
    "        \"charCount\" + ndoc : charCount,\n",
    "        \"rusCharCount\" + ndoc : rusCharCount,\n",
    "        \"engCharCount\" + ndoc : engCharCount,\n",
    "        \"digitsCount\" + ndoc : digitsCount     ,\n",
    "        \"exclamationMarkCount\" + ndoc : exclamationMarkCount,\n",
    "        \"questionMarkCount\" + ndoc : questionMarkCount,\n",
    "        \"wordPerSentence\" + ndoc : wordPerSentence,\n",
    "        \"charPerSentence\" + ndoc : charPerSentence,\n",
    "        \"rusCharPerSentence\" + ndoc : rusCharPerSentence,\n",
    "        \"engCharPerSentence\" + ndoc : engCharPerSentence,\n",
    "        \"numCharPerSentence\" + ndoc : numCharPerSentence,\n",
    "        \"charPerWord\" + ndoc : charPerWord,\n",
    "        \"rusCharPerWord\" + ndoc : rusCharPerWord,\n",
    "        \"engCharPerWord\" + ndoc : engCharPerWord,\n",
    "        \"numCharPerWord\" + ndoc : numCharPerWord,\n",
    "        \"rusCharRatio\" + ndoc : rusCharRatio,\n",
    "        \"engCharRatio\" + ndoc : engCharRatio,\n",
    "        \"rusCharVsEngChar\" + ndoc : rusCharVsEngChar,\n",
    "        \"engCharVsRusChar\" + ndoc : engCharVsRusChar,\n",
    "        \"numCharVsRusChar\" + ndoc : numCharVsRusChar,\n",
    "        \"numCharVsEngChar\" + ndoc : numCharVsEngChar\n",
    "    }\n",
    "#     statsFeat = \"\"\n",
    "#     for i,f in enumerate(stats):\n",
    "#         if f != 0:\n",
    "#             statsFeat += \"%s:%s \" % (i+1, f)\n",
    "#     statsFeat = statsFeat[:-1]    \n",
    "#     return statsFeat\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCleanSentence(text, stemmRequired = True,\n",
    "             correctWordRequired = True,\n",
    "             excludeStopwordsRequired = True):\n",
    "    \"\"\" Splits the text into words, discards stop words and applies stemmer. \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str - initial string\n",
    "    stemmRequired : bool - flag whether stemming required\n",
    "    correctWordRequired : bool - flag whether correction of words required     \n",
    "    \"\"\"\n",
    "    text = text.replace(\",\", \" \").replace(\".\", \" \")\n",
    "    cleanText = re.sub(u'[^a-zа-я0-9]', ' ', text.lower())\n",
    "    if correctWordRequired:\n",
    "        if excludeStopwordsRequired:\n",
    "            words = [correctWord(w) \\\n",
    "                    if not stemmRequired or re.search(\"[0-9a-z]\", w) \\\n",
    "                    else stemmer.stem(correctWord(w)) \\\n",
    "                    for w in cleanText.split() \\\n",
    "                    if len(w)>1 and w not in stopwords]\n",
    "        else:\n",
    "            words = [correctWord(w) \\\n",
    "                    if not stemmRequired or re.search(\"[0-9a-z]\", w) \\\n",
    "                    else stemmer.stem(correctWord(w)) \\\n",
    "                    for w in cleanText.split() \\\n",
    "                    if len(w)>1]\n",
    "    else:\n",
    "        if excludeStopwordsRequired:\n",
    "            words = [w \\\n",
    "                    if not stemmRequired or re.search(\"[0-9a-z]\", w) \\\n",
    "                    else stemmer.stem(w) \\\n",
    "                    for w in cleanText.split() \\\n",
    "                    if len(w)>1 and w not in stopwords]\n",
    "        else:\n",
    "            words = [w \\\n",
    "                    if not stemmRequired or re.search(\"[0-9a-z]\", w) \\\n",
    "                    else stemmer.stem(w) \\\n",
    "                    for w in cleanText.split() \\\n",
    "                    if len(w)>1]\n",
    "    cleanSentence = ' '.join(words)\n",
    "    return cleanSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "----- LOAD train_merged-part1\n",
      "----- LOAD train_merged-part2\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading...\")\n",
    "print(\"----- LOAD train_merged-part1\")\n",
    "pdtrain1 = pd.read_hdf(FOLDER + \"train_merged-part1.h\")\n",
    "print(\"----- LOAD train_merged-part2\")\n",
    "pdtrain2 = pd.read_hdf(FOLDER + \"train_merged-part2.h\")\n",
    "pdtrain = pdtrain1.append(pdtrain2)\n",
    "# print(\"----- LOAD test_merged\")\n",
    "# pdtest = pd.read_hdf(FOLDER + \"test_merged.h\")\n",
    "# pd_data = pdtrain.append(pdtest)\n",
    "\n",
    "del pdtrain1\n",
    "del pdtrain2\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract titles\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"Extract titles\")\n",
    "pd_titles_features = pdtrain[['itemID_1', 'itemID_2','title_1','title_2', 'isDuplicate']]\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Replacing NaN\")\n",
    "pd_titles_features['title_1'].fillna(\"\", inplace=True)\n",
    "pd_titles_features['title_2'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pdtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns = [\n",
    "# 'sentenceCount',\n",
    "# 'wordCount',\n",
    "# 'charCount',\n",
    "# 'rusCharCount',\n",
    "# 'engCharCount',\n",
    "# 'digitsCount',\n",
    "# 'exclamationMarkCount',\n",
    "# 'questionMarkCount',\n",
    "# 'wordPerSentence',\n",
    "# 'charPerSentence',\n",
    "# 'rusCharPerSentence',\n",
    "# 'engCharPerSentence',\n",
    "# 'numCharPerSentence',\n",
    "# 'charPerWord',\n",
    "# 'rusCharPerWord',\n",
    "# 'engCharPerWord',\n",
    "# 'numCharPerWord',\n",
    "# 'rusCharRatio',\n",
    "# 'engCharRatio',\n",
    "# 'rusCharVsEngChar',\n",
    "# 'engCharVsRusChar',\n",
    "# 'numCharVsRusChar',\n",
    "# 'numCharVsEngChar'\n",
    "# ]\n",
    "# test = pd.DataFrame(0.0, index=pd_titles_features.head().index, columns=columns)\n",
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing title_1\n",
      "Processing title_2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing title_1\")\n",
    "pd_titles_features = pd_titles_features.merge(pd_titles_features.title_1.apply(lambda x: pd.Series(getTextStatsFeat(x, '_1'))), \n",
    "           left_index=True, right_index=True)\n",
    "\n",
    "print(\"Processing title_2\")\n",
    "pd_titles_features = pd_titles_features.merge(pd_titles_features.title_2.apply(lambda x: pd.Series(getTextStatsFeat(x, '_2'))), \n",
    "           left_index=True, right_index=True)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_titles_features.to_hdf(\"titles_dumy_features.h\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del pd_titles_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "----- LOAD train_merged-part1\n",
      "----- LOAD train_merged-part2\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading...\")\n",
    "print(\"----- LOAD train_merged-part1\")\n",
    "pdtrain1 = pd.read_hdf(FOLDER + \"train_merged-part1.h\")\n",
    "print(\"----- LOAD train_merged-part2\")\n",
    "pdtrain2 = pd.read_hdf(FOLDER + \"train_merged-part2.h\")\n",
    "pdtrain = pdtrain1.append(pdtrain2)\n",
    "# print(\"----- LOAD test_merged\")\n",
    "# pdtest = pd.read_hdf(FOLDER + \"test_merged.h\")\n",
    "# pd_data = pdtrain.append(pdtest)\n",
    "\n",
    "del pdtrain1\n",
    "del pdtrain2\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract titles\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"Extract titles\")\n",
    "pd_description_features = pdtrain[['itemID_1', 'itemID_2','description_1','description_2', 'isDuplicate']]\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pdtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID_1</th>\n",
       "      <th>itemID_2</th>\n",
       "      <th>description_1</th>\n",
       "      <th>description_2</th>\n",
       "      <th>isDuplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4112648</td>\n",
       "      <td>Продам Камаз 6520 20 тонн</td>\n",
       "      <td>Продам Камаз 6520 20 тонн</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523245</td>\n",
       "      <td>739258</td>\n",
       "      <td>Продам в хорошем состоянии 2 пары ботинок для ...</td>\n",
       "      <td>Продам в хорошем состоянии сноуборд размер 150см</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>739258</td>\n",
       "      <td>2558827</td>\n",
       "      <td>Продам в хорошем состоянии сноуборд размер 150см</td>\n",
       "      <td>Продам новые крепления \\nЦена 2500 руб</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280620</td>\n",
       "      <td>970311</td>\n",
       "      <td>Продам или обмен мерседес бенц в хорошем состо...</td>\n",
       "      <td>Продам в хорошем состоянии,рестайлинг,двигател...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>970311</td>\n",
       "      <td>4402682</td>\n",
       "      <td>Продам в хорошем состоянии,рестайлинг,двигател...</td>\n",
       "      <td>Продам  ,автомат не пинает,масло от замены до ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID_1  itemID_2                                      description_1  \\\n",
       "0         1   4112648                          Продам Камаз 6520 20 тонн   \n",
       "1    523245    739258  Продам в хорошем состоянии 2 пары ботинок для ...   \n",
       "2    739258   2558827   Продам в хорошем состоянии сноуборд размер 150см   \n",
       "3    280620    970311  Продам или обмен мерседес бенц в хорошем состо...   \n",
       "4    970311   4402682  Продам в хорошем состоянии,рестайлинг,двигател...   \n",
       "\n",
       "                                       description_2  isDuplicate  \n",
       "0                          Продам Камаз 6520 20 тонн            1  \n",
       "1   Продам в хорошем состоянии сноуборд размер 150см            0  \n",
       "2             Продам новые крепления \\nЦена 2500 руб            0  \n",
       "3  Продам в хорошем состоянии,рестайлинг,двигател...            1  \n",
       "4  Продам  ,автомат не пинает,масло от замены до ...            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_description_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Replacing NaN\")\n",
    "pd_description_features['description_1'].fillna(\"\", inplace=True)\n",
    "pd_description_features['description_2'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing descriprion_1\n",
      "Processing descriprion_2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing descriprion_1\")\n",
    "pd_description_features = pd_description_features.merge(pd_description_features.description_1.apply(lambda x: pd.Series(getTextStatsFeat(getCleanSentence(x), '_1'))), \n",
    "           left_index=True, right_index=True)\n",
    "\n",
    "print(\"Processing descriprion_2\")\n",
    "pd_description_features = pd_description_features.merge(pd_description_features.description_1.apply(lambda x: pd.Series(getTextStatsFeat(getCleanSentence(x), '_2'))), \n",
    "           left_index=True, right_index=True)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd_titles_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-10f8da234f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd_titles_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"description_dumy_features.h\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DONE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd_titles_features' is not defined"
     ]
    }
   ],
   "source": [
    "pd_titles_features.to_hdf(\"description_dumy_features.h\", 'w')\n",
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
